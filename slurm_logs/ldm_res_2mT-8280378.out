[[36m2025-03-27 00:20:31,928[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2025-03-27 00:20:31,936[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
â”œâ”€â”€ data
â”‚   â””â”€â”€ _target_: src.data.downscaling_datamodule.DownscalingDataModule         
â”‚       data_dir: /usr/project/xtmp/par55/DiffScaler/data/                      
â”‚       static_vars:                                                            
â”‚         dtm_tif_file: /usr/project/xtmp/par55/DiffScaler/data//static_var/dtm_
â”‚         lc_tif_file: /usr/project/xtmp/par55/DiffScaler/data//static_var/land_
â”‚         lat_tif_file: /usr/project/xtmp/par55/DiffScaler/data//static_var/lat_
â”‚       target_vars:                                                            
â”‚         low_res:                                                              
â”‚         - 2mT                                                                 
â”‚         - PMSL                                                                
â”‚         - U10                                                                 
â”‚         - V10                                                                 
â”‚         - dp2mT                                                               
â”‚         - SST                                                                 
â”‚         - SNDPT                                                               
â”‚         - TP                                                                  
â”‚         - SSRadIn                                                             
â”‚         - Q850                                                                
â”‚         - T850                                                                
â”‚         - U850                                                                
â”‚         - V850                                                                
â”‚         - W850                                                                
â”‚         high_res:                                                             
â”‚         - 2mT                                                                 
â”‚       batch_size: 8                                                           
â”‚       num_workers: 8                                                          
â”‚       pin_memory: true                                                        
â”‚       crop_size: 512                                                          
â”‚       nn_lowres: false                                                        
â”‚                                                                               
â”œâ”€â”€ model
â”‚   â””â”€â”€ _target_: src.models.ldm_module.LatentDiffusion                         
â”‚       parameterization: v                                                     
â”‚       denoiser:                                                               
â”‚         _target_: src.models.components.ldm.denoiser.UNetModel                
â”‚         in_channels: 32                                                       
â”‚         model_channels: 256                                                   
â”‚         out_channels: 32                                                      
â”‚         num_res_blocks: 2                                                     
â”‚         attention_resolutions:                                                
â”‚         - 1                                                                   
â”‚         - 2                                                                   
â”‚         dims: 2                                                               
â”‚         channel_mult:                                                         
â”‚         - 1                                                                   
â”‚         - 2                                                                   
â”‚         - 4                                                                   
â”‚         num_heads: 8                                                          
â”‚         context_ch:                                                           
â”‚         - 256                                                                 
â”‚         - 512                                                                 
â”‚         - 1024                                                                
â”‚       autoencoder:                                                            
â”‚         _target_: src.models.ae_module.AutoencoderKL                          
â”‚         encoder:                                                              
â”‚           _target_: src.models.components.ae.SimpleConvEncoder                
â”‚           levels: 3                                                           
â”‚         decoder:                                                              
â”‚           _target_: src.models.components.ae.SimpleConvDecoder                
â”‚           levels: 3                                                           
â”‚         unet_regr:                                                            
â”‚           _target_: src.models.unet_module.UnetLitModule                      
â”‚           net:                                                                
â”‚             _target_: src.models.components.unet.DownscalingUnet              
â”‚             in_ch: 32                                                         
â”‚             out_ch: 1                                                         
â”‚             features:                                                         
â”‚             - 64                                                              
â”‚             - 128                                                             
â”‚             - 256                                                             
â”‚             - 512                                                             
â”‚           loss:                                                               
â”‚             _target_: torch.nn.MSELoss                                        
â”‚             reduction: mean                                                   
â”‚           optimizer: None                                                     
â”‚           ckpt_path: /usr/project/xtmp/par55/DiffScaler/pretrained_models/UNET
â”‚         ae_flag: residual                                                     
â”‚       context_encoder:                                                        
â”‚         _target_: src.models.components.ldm.conditioner.AFNOConditionerNetCasc
â”‚         autoencoder:                                                          
â”‚         - _target_: src.models.ae_module.AutoencoderKL                        
â”‚           encoder:                                                            
â”‚             _target_: src.models.components.ae.SimpleConvEncoder              
â”‚             in_dim: 18                                                        
â”‚             levels: 3                                                         
â”‚             ch_mult: 3                                                        
â”‚           decoder: None                                                       
â”‚         - _target_: src.models.ae_module.EncoderLRES                          
â”‚         train_autoenc: true                                                   
â”‚         cascade_depth: 3                                                      
â”‚         embed_dim:                                                            
â”‚         - 128                                                                 
â”‚         - 24                                                                  
â”‚         analysis_depth:                                                       
â”‚         - 4                                                                   
â”‚         - 4                                                                   
â”‚         afno_fusion: true                                                     
â”‚         input_size_ratios:                                                    
â”‚         - 1                                                                   
â”‚         - 1                                                                   
â”‚         embed_dim_out: 256                                                    
â”‚       lr: 0.0001                                                              
â”‚       ae_load_state_file: /usr/project/xtmp/par55/DiffScaler/pretrained_models
â”‚       pde_lambda: 0.5                                                         
â”‚       pde_mode: temp                                                          
â”‚       trainable_parts:                                                        
â”‚       - denoiser.input_blocks                                                 
â”‚       - denoiser.middle_block                                                 
â”‚                                                                               
â”œâ”€â”€ callbacks
â”‚   â””â”€â”€ model_checkpoint:                                                       
â”‚         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 
â”‚         dirpath: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-27
â”‚         filename: epoch_{epoch:03d}                                           
â”‚         monitor: val/loss                                                     
â”‚         verbose: false                                                        
â”‚         save_last: true                                                       
â”‚         save_top_k: 3                                                         
â”‚         mode: min                                                             
â”‚         auto_insert_metric_name: false                                        
â”‚         save_weights_only: false                                              
â”‚         every_n_train_steps: null                                             
â”‚         train_time_interval: null                                             
â”‚         every_n_epochs: null                                                  
â”‚         save_on_train_epoch_end: null                                         
â”‚       early_stopping:                                                         
â”‚         _target_: lightning.pytorch.callbacks.EarlyStopping                   
â”‚         monitor: val/loss                                                     
â”‚         min_delta: 0.0                                                        
â”‚         patience: 5                                                           
â”‚         verbose: false                                                        
â”‚         mode: min                                                             
â”‚         strict: true                                                          
â”‚         check_finite: true                                                    
â”‚         stopping_threshold: null                                              
â”‚         divergence_threshold: null                                            
â”‚         check_on_train_epoch_end: null                                        
â”‚       model_summary:                                                          
â”‚         _target_: lightning.pytorch.callbacks.RichModelSummary                
â”‚         max_depth: -1                                                         
â”‚       rich_progress_bar:                                                      
â”‚         _target_: lightning.pytorch.callbacks.RichProgressBar                 
â”‚                                                                               
â”œâ”€â”€ logger
â”‚   â””â”€â”€ tensorboard:                                                            
â”‚         _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger     
â”‚         save_dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-2
â”‚         name: null                                                            
â”‚         log_graph: false                                                      
â”‚         default_hp_metric: true                                               
â”‚         prefix: ''                                                            
â”‚                                                                               
â”œâ”€â”€ trainer
â”‚   â””â”€â”€ _target_: lightning.pytorch.trainer.Trainer                             
â”‚       default_root_dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/202
â”‚       min_epochs: 10                                                          
â”‚       max_epochs: 60                                                          
â”‚       accelerator: gpu                                                        
â”‚       devices: 4                                                              
â”‚       strategy: ddp_find_unused_parameters_true                               
â”‚       check_val_every_n_epoch: 1                                              
â”‚       deterministic: false                                                    
â”‚                                                                               
â”œâ”€â”€ paths
â”‚   â””â”€â”€ root_dir: /usr/project/xtmp/par55/DiffScaler                            
â”‚       data_dir: /usr/project/xtmp/par55/DiffScaler/data/                      
â”‚       log_dir: /usr/project/xtmp/par55/DiffScaler/logs/                       
â”‚       output_dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-2
â”‚       work_dir: /usr/project/xtmp/par55/DiffScaler                            
â”‚       pretrained_models_dir: /usr/project/xtmp/par55/DiffScaler/pretrained_mod
â”‚                                                                               
â”œâ”€â”€ extras
â”‚   â””â”€â”€ ignore_warnings: false                                                  
â”‚       enforce_tags: true                                                      
â”‚       print_config: true                                                      
â”‚                                                                               
â”œâ”€â”€ task_name
â”‚   â””â”€â”€ train                                                                   
â”œâ”€â”€ tags
â”‚   â””â”€â”€ ['downscaling', 'ldm_res_2mT']                                          
â”œâ”€â”€ train
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ test
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ compile
â”‚   â””â”€â”€ False                                                                   
â”œâ”€â”€ ckpt_path
â”‚   â””â”€â”€ /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT co
â”œâ”€â”€ seed
â”‚   â””â”€â”€ 42                                                                      
â”œâ”€â”€ optimized_metric
â”‚   â””â”€â”€ val/loss                                                                
â””â”€â”€ load_optimizer_state
    â””â”€â”€ False                                                                   
[[36m2025-03-27 00:20:32,033[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>[0m
[[36m2025-03-27 00:20:32,642[0m][[34mnumexpr.utils[0m][[32mINFO[0m] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.[0m
[[36m2025-03-27 00:20:32,643[0m][[34mnumexpr.utils[0m][[32mINFO[0m] - NumExpr defaulting to 8 threads.[0m
[[36m2025-03-27 00:20:33,900[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating model <src.models.ldm_module.LatentDiffusion>[0m
Restored from /usr/project/xtmp/par55/DiffScaler/pretrained_models/UNET_2mT.ckpt with 0 missing and 0 unexpected keys
Unfreezing parameter: denoiser.input_blocks.0.0.weight
Unfreezing parameter: denoiser.input_blocks.0.0.bias
Unfreezing parameter: denoiser.input_blocks.1.0.in_layers.2.weight
Unfreezing parameter: denoiser.input_blocks.1.0.in_layers.2.bias
Unfreezing parameter: denoiser.input_blocks.1.0.emb_layers.1.weight
Unfreezing parameter: denoiser.input_blocks.1.0.emb_layers.1.bias
Unfreezing parameter: denoiser.input_blocks.1.0.out_layers.3.weight
Unfreezing parameter: denoiser.input_blocks.1.0.out_layers.3.bias
Unfreezing parameter: denoiser.input_blocks.1.1.pre_proj.weight
Unfreezing parameter: denoiser.input_blocks.1.1.pre_proj.bias
Unfreezing parameter: denoiser.input_blocks.1.1.filter.w1
Unfreezing parameter: denoiser.input_blocks.1.1.filter.b1
Unfreezing parameter: denoiser.input_blocks.1.1.filter.w2
Unfreezing parameter: denoiser.input_blocks.1.1.filter.b2
Unfreezing parameter: denoiser.input_blocks.1.1.mlp.fc1.weight
Unfreezing parameter: denoiser.input_blocks.1.1.mlp.fc1.bias
Unfreezing parameter: denoiser.input_blocks.1.1.mlp.fc2.weight
Unfreezing parameter: denoiser.input_blocks.1.1.mlp.fc2.bias
Unfreezing parameter: denoiser.input_blocks.2.0.in_layers.2.weight
Unfreezing parameter: denoiser.input_blocks.2.0.in_layers.2.bias
Unfreezing parameter: denoiser.input_blocks.2.0.emb_layers.1.weight
Unfreezing parameter: denoiser.input_blocks.2.0.emb_layers.1.bias
Unfreezing parameter: denoiser.input_blocks.2.0.out_layers.3.weight
Unfreezing parameter: denoiser.input_blocks.2.0.out_layers.3.bias
Unfreezing parameter: denoiser.input_blocks.2.1.pre_proj.weight
Unfreezing parameter: denoiser.input_blocks.2.1.pre_proj.bias
Unfreezing parameter: denoiser.input_blocks.2.1.filter.w1
Unfreezing parameter: denoiser.input_blocks.2.1.filter.b1
Unfreezing parameter: denoiser.input_blocks.2.1.filter.w2
Unfreezing parameter: denoiser.input_blocks.2.1.filter.b2
Unfreezing parameter: denoiser.input_blocks.2.1.mlp.fc1.weight
Unfreezing parameter: denoiser.input_blocks.2.1.mlp.fc1.bias
Unfreezing parameter: denoiser.input_blocks.2.1.mlp.fc2.weight
Unfreezing parameter: denoiser.input_blocks.2.1.mlp.fc2.bias
Unfreezing parameter: denoiser.input_blocks.3.0.op.weight
Unfreezing parameter: denoiser.input_blocks.3.0.op.bias
Unfreezing parameter: denoiser.input_blocks.4.0.in_layers.2.weight
Unfreezing parameter: denoiser.input_blocks.4.0.in_layers.2.bias
Unfreezing parameter: denoiser.input_blocks.4.0.emb_layers.1.weight
Unfreezing parameter: denoiser.input_blocks.4.0.emb_layers.1.bias
Unfreezing parameter: denoiser.input_blocks.4.0.out_layers.3.weight
Unfreezing parameter: denoiser.input_blocks.4.0.out_layers.3.bias
Unfreezing parameter: denoiser.input_blocks.4.0.skip_connection.weight
Unfreezing parameter: denoiser.input_blocks.4.0.skip_connection.bias
Unfreezing parameter: denoiser.input_blocks.4.1.pre_proj.weight
Unfreezing parameter: denoiser.input_blocks.4.1.pre_proj.bias
Unfreezing parameter: denoiser.input_blocks.4.1.filter.w1
Unfreezing parameter: denoiser.input_blocks.4.1.filter.b1
Unfreezing parameter: denoiser.input_blocks.4.1.filter.w2
Unfreezing parameter: denoiser.input_blocks.4.1.filter.b2
Unfreezing parameter: denoiser.input_blocks.4.1.mlp.fc1.weight
Unfreezing parameter: denoiser.input_blocks.4.1.mlp.fc1.bias
Unfreezing parameter: denoiser.input_blocks.4.1.mlp.fc2.weight
Unfreezing parameter: denoiser.input_blocks.4.1.mlp.fc2.bias
Unfreezing parameter: denoiser.input_blocks.5.0.in_layers.2.weight
Unfreezing parameter: denoiser.input_blocks.5.0.in_layers.2.bias
Unfreezing parameter: denoiser.input_blocks.5.0.emb_layers.1.weight
Unfreezing parameter: denoiser.input_blocks.5.0.emb_layers.1.bias
Unfreezing parameter: denoiser.input_blocks.5.0.out_layers.3.weight
Unfreezing parameter: denoiser.input_blocks.5.0.out_layers.3.bias
Unfreezing parameter: denoiser.input_blocks.5.1.pre_proj.weight
Unfreezing parameter: denoiser.input_blocks.5.1.pre_proj.bias
Unfreezing parameter: denoiser.input_blocks.5.1.filter.w1
Unfreezing parameter: denoiser.input_blocks.5.1.filter.b1
Unfreezing parameter: denoiser.input_blocks.5.1.filter.w2
Unfreezing parameter: denoiser.input_blocks.5.1.filter.b2
Unfreezing parameter: denoiser.input_blocks.5.1.mlp.fc1.weight
Unfreezing parameter: denoiser.input_blocks.5.1.mlp.fc1.bias
Unfreezing parameter: denoiser.input_blocks.5.1.mlp.fc2.weight
Unfreezing parameter: denoiser.input_blocks.5.1.mlp.fc2.bias
Unfreezing parameter: denoiser.input_blocks.6.0.op.weight
Unfreezing parameter: denoiser.input_blocks.6.0.op.bias
Unfreezing parameter: denoiser.input_blocks.7.0.in_layers.2.weight
Unfreezing parameter: denoiser.input_blocks.7.0.in_layers.2.bias
Unfreezing parameter: denoiser.input_blocks.7.0.emb_layers.1.weight
Unfreezing parameter: denoiser.input_blocks.7.0.emb_layers.1.bias
Unfreezing parameter: denoiser.input_blocks.7.0.out_layers.3.weight
Unfreezing parameter: denoiser.input_blocks.7.0.out_layers.3.bias
Unfreezing parameter: denoiser.input_blocks.7.0.skip_connection.weight
Unfreezing parameter: denoiser.input_blocks.7.0.skip_connection.bias
Unfreezing parameter: denoiser.input_blocks.8.0.in_layers.2.weight
Unfreezing parameter: denoiser.input_blocks.8.0.in_layers.2.bias
Unfreezing parameter: denoiser.input_blocks.8.0.emb_layers.1.weight
Unfreezing parameter: denoiser.input_blocks.8.0.emb_layers.1.bias
Unfreezing parameter: denoiser.input_blocks.8.0.out_layers.3.weight
Unfreezing parameter: denoiser.input_blocks.8.0.out_layers.3.bias
Unfreezing parameter: denoiser.middle_block.0.in_layers.2.weight
Unfreezing parameter: denoiser.middle_block.0.in_layers.2.bias
Unfreezing parameter: denoiser.middle_block.0.emb_layers.1.weight
Unfreezing parameter: denoiser.middle_block.0.emb_layers.1.bias
Unfreezing parameter: denoiser.middle_block.0.out_layers.3.weight
Unfreezing parameter: denoiser.middle_block.0.out_layers.3.bias
Unfreezing parameter: denoiser.middle_block.1.pre_proj.weight
Unfreezing parameter: denoiser.middle_block.1.pre_proj.bias
Unfreezing parameter: denoiser.middle_block.1.filter.w1
Unfreezing parameter: denoiser.middle_block.1.filter.b1
Unfreezing parameter: denoiser.middle_block.1.filter.w2
Unfreezing parameter: denoiser.middle_block.1.filter.b2
Unfreezing parameter: denoiser.middle_block.1.mlp.fc1.weight
Unfreezing parameter: denoiser.middle_block.1.mlp.fc1.bias
Unfreezing parameter: denoiser.middle_block.1.mlp.fc2.weight
Unfreezing parameter: denoiser.middle_block.1.mlp.fc2.bias
Unfreezing parameter: denoiser.middle_block.2.in_layers.2.weight
Unfreezing parameter: denoiser.middle_block.2.in_layers.2.bias
Unfreezing parameter: denoiser.middle_block.2.emb_layers.1.weight
Unfreezing parameter: denoiser.middle_block.2.emb_layers.1.bias
Unfreezing parameter: denoiser.middle_block.2.out_layers.3.weight
Unfreezing parameter: denoiser.middle_block.2.out_layers.3.bias
[[36m2025-03-27 00:20:39,542[0m][[34m__main__[0m][[32mINFO[0m] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT copy.ckpt without optimizer state.[0m
[[36m2025-03-27 00:20:58,182[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating callbacks...[0m
[[36m2025-03-27 00:20:58,183[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-03-27 00:20:58,190[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2025-03-27 00:20:58,191[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-03-27 00:20:58,191[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-03-27 00:20:58,193[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating loggers...[0m
[[36m2025-03-27 00:20:58,193[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>[0m
[[36m2025-03-27 00:20:58,194[0m][[34m__main__[0m][[32mINFO[0m] - Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
[[36m2025-03-27 00:20:59,500[0m][[34m__main__[0m][[32mINFO[0m] - Logging hyperparameters![0m
