[2025-03-21 10:56:22,729][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-21 10:56:22,740][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-21 10:56:22,825][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-21 10:56:23,281][numexpr.utils][INFO] - Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-21 10:56:23,281][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-21 10:56:24,037][__main__][INFO] - Instantiating model <src.models.unet_module.UnetLitModule>
[2025-03-21 10:56:24,301][__main__][INFO] - Instantiating callbacks...
[2025-03-21 10:56:24,302][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-21 10:56:24,311][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-21 10:56:24,312][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-21 10:56:24,312][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-21 10:56:24,313][__main__][INFO] - Instantiating loggers...
[2025-03-21 10:56:24,313][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-21 10:56:24,316][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-21 10:56:25,699][__main__][INFO] - Logging hyperparameters!
[2025-03-21 10:56:35,125][__main__][INFO] - Starting training!
[2025-03-21 10:56:35,347][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 87, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 42, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 934, in _run
    call._call_setup_hook(self)  # allow user to setup lightning_module in accelerator environment
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 83, in _call_setup_hook
    _call_lightning_datamodule_hook(trainer, "setup", stage=fn)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 164, in _call_lightning_datamodule_hook
    return fn(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/data/downscaling_datamodule.py", line 71, in setup
    dataset = DownscalingDataset(self.hparams.data_dir, self.hparams.target_vars, self.hparams.nn_lowres, self.hparams.static_vars,
  File "/usr/project/xtmp/par55/DiffScaler/src/data/components/downscaling_dataset.py", line 22, in __init__
    self.metadata = pd.read_csv(self.dataset_dir + self.metadata_file_name, parse_dates=['ref_time'])
  File "/home/users/par55/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/users/par55/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/users/par55/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/users/par55/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/home/users/par55/.local/lib/python3.10/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: '/usr/project/xtmp/par55/DiffScaler/data/metadata.csv'
[2025-03-21 10:56:35,354][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-21_10-56-22
[2025-03-21 11:48:35,944][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-21 11:48:35,951][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-21 11:48:36,033][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-21 11:48:36,260][numexpr.utils][INFO] - Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-21 11:48:36,260][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-21 11:48:36,882][__main__][INFO] - Instantiating model <src.models.unet_module.UnetLitModule>
[2025-03-21 11:48:37,132][__main__][INFO] - Instantiating callbacks...
[2025-03-21 11:48:37,133][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-21 11:48:37,136][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-21 11:48:37,138][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-21 11:48:37,138][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-21 11:48:37,139][__main__][INFO] - Instantiating loggers...
[2025-03-21 11:48:37,139][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-21 11:48:37,141][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-21 11:48:38,351][__main__][INFO] - Logging hyperparameters!
[2025-03-21 11:48:43,054][__main__][INFO] - Starting training!
[2025-03-21 11:51:32,054][__main__][INFO] - Starting testing!
[2025-03-21 11:51:32,054][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-03-21 11:57:03,719][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-21 11:57:03,726][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-21 11:57:03,815][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-21 11:57:04,300][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-21 11:57:04,300][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-21 11:57:05,387][__main__][INFO] - Instantiating model <src.models.unet_module.UnetLitModule>
[2025-03-21 11:57:05,712][__main__][INFO] - Instantiating callbacks...
[2025-03-21 11:57:05,713][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-21 11:57:05,721][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-21 11:57:05,722][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-21 11:57:05,723][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-21 11:57:05,724][__main__][INFO] - Instantiating loggers...
[2025-03-21 11:57:05,724][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-21 11:57:05,726][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-21 11:57:07,008][__main__][INFO] - Logging hyperparameters!
[2025-03-21 11:57:15,943][__main__][INFO] - Starting training!
[2025-03-21 16:38:31,880][__main__][INFO] - Starting testing!
[2025-03-21 16:38:31,881][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-03-21 16:42:26,985][__main__][INFO] - Best ckpt path: None
[2025-03-21 16:42:26,987][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-21_11-57-03
[2025-03-24 23:54:13,010][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-24 23:54:13,020][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-24 23:54:13,143][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-24 23:54:13,732][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-24 23:54:13,733][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-24 23:54:14,903][__main__][INFO] - Instantiating model <src.models.unet_module.UnetLitModule>
[2025-03-24 23:54:15,216][__main__][INFO] - Instantiating callbacks...
[2025-03-24 23:54:15,217][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-24 23:54:15,230][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-24 23:54:15,231][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-24 23:54:15,232][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-24 23:54:15,233][__main__][INFO] - Instantiating loggers...
[2025-03-24 23:54:15,233][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-24 23:54:15,235][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-24 23:54:16,406][__main__][INFO] - Logging hyperparameters!
[2025-03-24 23:54:26,907][__main__][INFO] - Starting training!
[2025-03-24 23:58:20,763][__main__][INFO] - Starting testing!
[2025-03-24 23:58:20,764][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-03-24 23:58:23,611][__main__][INFO] - Best ckpt path: None
[2025-03-24 23:58:23,614][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-24_23-54-12
[2025-03-24 23:58:42,237][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-24 23:58:42,246][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-24 23:58:42,344][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-24 23:58:42,517][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-24 23:58:42,517][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-24 23:58:43,328][__main__][INFO] - Instantiating model <src.models.unet_module.UnetLitModule>
[2025-03-24 23:58:43,590][__main__][INFO] - Instantiating callbacks...
[2025-03-24 23:58:43,591][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-24 23:58:43,594][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-24 23:58:43,596][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-24 23:58:43,596][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-24 23:58:43,597][__main__][INFO] - Instantiating loggers...
[2025-03-24 23:58:43,597][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-24 23:58:43,599][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-24 23:58:44,759][__main__][INFO] - Logging hyperparameters!
[2025-03-24 23:58:50,153][__main__][INFO] - Starting training!
[2025-03-24 23:59:06,891][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-24 23:59:06,913][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-25 00:00:01,631][torch.nn.parallel.distributed][INFO] - Reducer buckets have been rebuilt in this iteration.
[2025-03-25 14:22:39,651][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-25 14:22:39,658][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-25 14:22:39,762][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-25 14:22:39,994][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-25 14:22:39,995][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-25 14:22:40,879][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-25 14:22:46,431][__main__][INFO] - Instantiating callbacks...
[2025-03-25 14:22:46,432][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-25 14:22:46,436][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-25 14:22:46,437][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-25 14:22:46,438][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-25 14:22:46,438][__main__][INFO] - Instantiating loggers...
[2025-03-25 14:22:46,439][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-25 14:22:46,441][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-25 14:22:47,666][__main__][INFO] - Logging hyperparameters!
[2025-03-25 14:22:53,663][__main__][INFO] - Starting training!
[2025-03-25 14:23:18,004][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-25 14:23:18,004][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-25 14:24:41,604][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 87, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 201, in run
    self.advance()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 285, in optimizer_step
    super().optimizer_step(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 256, in optimizer_step
    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 33, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 148, in step
    loss = closure()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py", line 101, in _wrap_closure
    closure_result = closure()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 140, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 126, in closure
    step_output = self._step_fn()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 307, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 328, in training_step
    return self.model(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1139, in forward
    if torch.is_grad_enabled() and self.reducer._rebuild_buckets():
RuntimeError: It looks like your LightningModule has parameters that were not used in producing the loss returned by training_step. If this is intentional, you must enable the detection of unused parameters in DDP, either by setting the string value `strategy='ddp_find_unused_parameters_true'` or by setting the flag in the strategy with `strategy=DDPStrategy(find_unused_parameters=True)`.
[2025-03-25 14:24:41,623][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-25_14-22-39
[2025-03-25 17:31:35,154][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-25 17:31:35,162][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-25 17:31:35,270][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-25 17:31:35,859][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-25 17:31:35,859][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-25 17:31:37,090][__main__][INFO] - Instantiating model <src.models.unet_module.UnetLitModule>
[2025-03-25 17:31:37,387][__main__][INFO] - Instantiating callbacks...
[2025-03-25 17:31:37,388][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-25 17:31:37,398][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-25 17:31:37,399][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-25 17:31:37,400][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-25 17:31:37,401][__main__][INFO] - Instantiating loggers...
[2025-03-25 17:31:37,401][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-25 17:31:37,403][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-25 17:31:38,635][__main__][INFO] - Logging hyperparameters!
[2025-03-25 17:31:49,837][__main__][INFO] - Starting training!
[2025-03-25 17:32:08,666][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-25 17:32:08,688][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-25 17:33:07,723][torch.nn.parallel.distributed][INFO] - Reducer buckets have been rebuilt in this iteration.
[2025-03-25 17:54:17,607][__main__][INFO] - Starting testing!
[2025-03-25 17:54:17,620][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-03-25 17:54:42,519][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 97, in train
    trainer.test(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 735, in test
    return call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 778, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1009, in _run_stage
    return self._evaluation_loop.run()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 115, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 380, in _evaluation_step
    call._call_callback_hooks(trainer, hook_name, output, *step_kwargs.values())
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 193, in _call_callback_hooks
    fn(trainer, trainer.lightning_module, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/callbacks/progress/rich_progress.py", line 522, in on_test_batch_end
    assert self.test_progress_bar_id is not None
AssertionError
[2025-03-25 17:54:42,530][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-25_17-31-35
[2025-03-25 18:35:15,346][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-25 18:35:15,352][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-25 18:35:15,542][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-25 18:35:15,744][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-25 18:35:15,744][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-25 18:35:16,624][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-25 18:35:31,040][__main__][INFO] - Instantiating callbacks...
[2025-03-25 18:35:31,040][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-25 18:35:31,044][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-25 18:35:31,046][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-25 18:35:31,046][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-25 18:35:31,047][__main__][INFO] - Instantiating loggers...
[2025-03-25 18:35:31,047][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-25 18:35:31,050][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-25 18:35:32,477][__main__][INFO] - Logging hyperparameters!
[2025-03-25 18:35:38,056][__main__][INFO] - Starting training!
[2025-03-25 18:36:27,338][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-25 18:36:27,339][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-25 18:40:42,534][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-25 18:40:42,542][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-25 18:40:42,621][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-25 18:40:42,806][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-25 18:40:42,806][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-25 18:40:43,580][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-25 18:40:47,013][__main__][INFO] - Instantiating callbacks...
[2025-03-25 18:40:47,015][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-25 18:40:47,019][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-25 18:40:47,020][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-25 18:40:47,021][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-25 18:40:47,022][__main__][INFO] - Instantiating loggers...
[2025-03-25 18:40:47,023][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-25 18:40:47,025][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-25 18:40:48,313][__main__][INFO] - Logging hyperparameters!
[2025-03-25 18:40:54,281][__main__][INFO] - Starting training!
[2025-03-25 18:41:18,003][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-25 18:41:18,003][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-25 18:42:40,425][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 87, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 201, in run
    self.advance()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 285, in optimizer_step
    super().optimizer_step(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 256, in optimizer_step
    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 33, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 148, in step
    loss = closure()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py", line 101, in _wrap_closure
    closure_result = closure()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 140, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 126, in closure
    step_output = self._step_fn()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 307, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 328, in training_step
    return self.model(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1139, in forward
    if torch.is_grad_enabled() and self.reducer._rebuild_buckets():
RuntimeError: It looks like your LightningModule has parameters that were not used in producing the loss returned by training_step. If this is intentional, you must enable the detection of unused parameters in DDP, either by setting the string value `strategy='ddp_find_unused_parameters_true'` or by setting the flag in the strategy with `strategy=DDPStrategy(find_unused_parameters=True)`.
[2025-03-25 18:42:40,440][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-25_18-40-42
[2025-03-25 18:46:27,736][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-25 18:46:27,743][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-25 18:46:27,828][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-25 18:46:28,057][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-25 18:46:28,058][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-25 18:46:28,891][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-25 18:46:32,291][__main__][INFO] - Instantiating callbacks...
[2025-03-25 18:46:32,292][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-25 18:46:32,296][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-25 18:46:32,297][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-25 18:46:32,298][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-25 18:46:32,299][__main__][INFO] - Instantiating loggers...
[2025-03-25 18:46:32,299][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-25 18:46:32,302][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-25 18:46:33,550][__main__][INFO] - Logging hyperparameters!
[2025-03-25 18:46:39,348][__main__][INFO] - Starting training!
[2025-03-25 18:47:04,662][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-25 18:47:04,663][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-25 18:48:30,105][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 87, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 201, in run
    self.advance()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 285, in optimizer_step
    super().optimizer_step(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 256, in optimizer_step
    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 33, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 148, in step
    loss = closure()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py", line 101, in _wrap_closure
    closure_result = closure()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 140, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 126, in closure
    step_output = self._step_fn()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 307, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 328, in training_step
    return self.model(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/overrides/base.py", line 90, in forward
    output = self._forward_module.training_step(*inputs, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 231, in training_step
    loss = self.shared_step(batch)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 228, in shared_step
    return self(y, context=context)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 213, in forward
    return self.p_losses(x, t, *args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 198, in p_losses
    denoiser_out = self.denoiser(x_noisy, t, context=context)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/components/ldm/denoiser/unet.py", line 413, in forward
    h = module(h, emb, context)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/components/ldm/denoiser/unet.py", line 101, in forward
    x = layer(x, context[img_shape])
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/components/ldm/afno.py", line 145, in forward
    xy = self.filter(self.norm2(xy)) + xy # AFNO filter
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/components/ldm/afno.py", line 95, in forward
    x = torch.fft.irfft2(x, s=(H, W), dim=(1,2), norm="ortho")
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 23.67 GiB total capacity; 22.19 GiB already allocated; 52.56 MiB free; 22.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2025-03-25 18:48:30,122][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-25_18-46-27
[2025-03-25 19:57:50,932][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-25 19:57:50,940][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-25 19:57:51,144][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-25 19:57:51,379][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-25 19:57:51,379][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-25 19:57:52,293][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-25 19:58:05,176][__main__][INFO] - Instantiating callbacks...
[2025-03-25 19:58:05,182][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-25 19:58:05,186][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-25 19:58:05,187][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-25 19:58:05,188][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-25 19:58:05,189][__main__][INFO] - Instantiating loggers...
[2025-03-25 19:58:05,189][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-25 19:58:05,192][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-25 19:58:06,641][__main__][INFO] - Logging hyperparameters!
[2025-03-25 19:58:12,551][__main__][INFO] - Starting training!
[2025-03-25 19:58:58,507][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-25 19:58:58,507][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 01:24:42,579][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 01:24:42,587][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 01:24:42,687][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 01:24:42,968][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 01:24:42,968][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 01:24:43,879][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 01:24:48,764][__main__][INFO] - Instantiating callbacks...
[2025-03-26 01:24:48,765][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 01:24:48,769][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 01:24:48,771][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 01:24:48,772][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 01:24:48,772][__main__][INFO] - Instantiating loggers...
[2025-03-26 01:24:48,773][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 01:24:48,776][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 01:24:50,067][__main__][INFO] - Logging hyperparameters!
[2025-03-26 01:24:56,145][__main__][INFO] - Starting training!
[2025-03-26 01:25:19,992][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 01:25:19,993][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 01:25:22,395][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 87, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 939, in _run
    self._checkpoint_connector._restore_modules_and_callbacks(ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 395, in _restore_modules_and_callbacks
    self.resume_start(checkpoint_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 82, in resume_start
    loaded_checkpoint = self.trainer.strategy.load_checkpoint(checkpoint_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 348, in load_checkpoint
    return self.checkpoint_io.load_checkpoint(checkpoint_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/fabric/plugins/io/torch_io.py", line 87, in load_checkpoint
    raise FileNotFoundError(f"Checkpoint at {path} not found. Aborting training.")
FileNotFoundError: Checkpoint at /home/gabriele/Documents/fbk/icsc/downscaling-hydra/logs/train/runs/2023-12-29_15-55-26/checkpoints/last_updated_patience.ckpt not found. Aborting training.
[2025-03-26 01:25:22,403][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_01-24-42
[2025-03-26 01:28:21,883][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 01:28:21,891][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 01:28:21,980][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 01:28:22,216][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 01:28:22,216][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 01:28:23,154][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 01:28:25,819][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_01-28-21
[2025-03-26 01:28:43,806][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 01:28:43,814][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 01:28:43,902][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 01:28:44,065][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 01:28:44,065][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 01:28:44,668][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 01:28:48,077][__main__][INFO] - Instantiating callbacks...
[2025-03-26 01:28:48,078][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 01:28:48,083][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 01:28:48,084][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 01:28:48,085][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 01:28:48,086][__main__][INFO] - Instantiating loggers...
[2025-03-26 01:28:48,086][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 01:28:48,089][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 01:28:49,368][__main__][INFO] - Logging hyperparameters!
[2025-03-26 01:28:55,337][__main__][INFO] - Starting training!
[2025-03-26 01:29:18,759][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 01:29:18,759][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 01:30:45,106][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 87, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 201, in run
    self.advance()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 285, in optimizer_step
    super().optimizer_step(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 256, in optimizer_step
    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 33, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 148, in step
    loss = closure()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py", line 101, in _wrap_closure
    closure_result = closure()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 140, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 126, in closure
    step_output = self._step_fn()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 307, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 328, in training_step
    return self.model(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/overrides/base.py", line 90, in forward
    output = self._forward_module.training_step(*inputs, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 231, in training_step
    loss = self.shared_step(batch)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 228, in shared_step
    return self(y, context=context)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 213, in forward
    return self.p_losses(x, t, *args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 198, in p_losses
    denoiser_out = self.denoiser(x_noisy, t, context=context)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/components/ldm/denoiser/unet.py", line 413, in forward
    h = module(h, emb, context)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/components/ldm/denoiser/unet.py", line 101, in forward
    x = layer(x, context[img_shape])
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/components/ldm/afno.py", line 145, in forward
    xy = self.filter(self.norm2(xy)) + xy # AFNO filter
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/components/ldm/afno.py", line 95, in forward
    x = torch.fft.irfft2(x, s=(H, W), dim=(1,2), norm="ortho")
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 23.67 GiB total capacity; 22.07 GiB already allocated; 32.56 MiB free; 22.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2025-03-26 01:30:45,130][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_01-28-43
[2025-03-26 01:32:07,151][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 01:32:07,158][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 01:32:07,368][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 01:32:07,594][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 01:32:07,594][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 01:32:08,483][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 01:32:21,496][__main__][INFO] - Instantiating callbacks...
[2025-03-26 01:32:21,497][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 01:32:21,500][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 01:32:21,507][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 01:32:21,521][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 01:32:21,522][__main__][INFO] - Instantiating loggers...
[2025-03-26 01:32:21,523][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 01:32:21,525][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 01:32:22,964][__main__][INFO] - Logging hyperparameters!
[2025-03-26 01:32:28,808][__main__][INFO] - Starting training!
[2025-03-26 01:33:11,865][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 01:33:11,865][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 01:44:58,705][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 01:44:58,713][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 01:44:58,796][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 01:44:59,020][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 01:44:59,020][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 01:44:59,956][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 01:45:03,422][__main__][INFO] - Instantiating callbacks...
[2025-03-26 01:45:03,423][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 01:45:03,427][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 01:45:03,428][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 01:45:03,429][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 01:45:03,430][__main__][INFO] - Instantiating loggers...
[2025-03-26 01:45:03,430][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 01:45:03,432][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 01:45:04,706][__main__][INFO] - Logging hyperparameters!
[2025-03-26 01:45:10,805][__main__][INFO] - Starting training!
[2025-03-26 01:45:34,057][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 01:45:34,058][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 01:46:18,779][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 87, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1014, in _run_stage
    self._run_sanity_check()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1043, in _run_sanity_check
    val_loop.run()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 115, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 375, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_kwargs.values())
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 336, in validation_step
    return self.model(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/overrides/base.py", line 102, in forward
    return self._forward_module.validation_step(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 256, in validation_step
    with self.ema_scope():
  File "/usr/lib/python3.10/contextlib.py", line 135, in __enter__
    return next(self.gen)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 144, in ema_scope
    self.denoiser_ema.copy_to(self.denoiser)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/components/ldm/denoiser/ema.py", line 53, in copy_to
    assert not key in self.m_name2s_name
AssertionError
[2025-03-26 01:46:18,792][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_01-44-58
[2025-03-26 01:47:53,060][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 01:47:53,068][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 01:47:53,153][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 01:47:53,383][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 01:47:53,383][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 01:47:54,193][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 01:47:57,577][__main__][INFO] - Instantiating callbacks...
[2025-03-26 01:47:57,578][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 01:47:57,582][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 01:47:57,583][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 01:47:57,584][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 01:47:57,585][__main__][INFO] - Instantiating loggers...
[2025-03-26 01:47:57,585][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 01:47:57,587][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 01:47:58,846][__main__][INFO] - Logging hyperparameters!
[2025-03-26 01:48:04,779][__main__][INFO] - Starting training!
[2025-03-26 01:48:28,355][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 01:48:28,355][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 01:49:13,530][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 87, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 964, in _run
    self._checkpoint_connector.restore_training_state()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 297, in restore_training_state
    self.restore_optimizers_and_schedulers()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 366, in restore_optimizers_and_schedulers
    self.restore_optimizers()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 381, in restore_optimizers
    self.trainer.strategy.load_optimizer_state_dict(self._loaded_checkpoint)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 357, in load_optimizer_state_dict
    optimizer.load_state_dict(opt_state)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 390, in load_state_dict
    raise ValueError("loaded state dict contains a parameter group "
ValueError: loaded state dict contains a parameter group that doesn't match the size of optimizer's group
[2025-03-26 01:49:13,535][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_01-47-52
[2025-03-26 01:50:06,485][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 01:50:06,493][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 01:50:06,576][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 01:50:06,765][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 01:50:06,765][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 01:50:07,428][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 01:50:10,980][__main__][INFO] - Instantiating callbacks...
[2025-03-26 01:50:10,981][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 01:50:10,985][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 01:50:10,986][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 01:50:10,987][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 01:50:10,988][__main__][INFO] - Instantiating loggers...
[2025-03-26 01:50:10,988][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 01:50:10,990][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 01:50:12,287][__main__][INFO] - Logging hyperparameters!
[2025-03-26 01:50:17,432][__main__][INFO] - Starting training!
[2025-03-26 01:50:44,030][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 01:50:44,030][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 01:50:56,224][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 87, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 939, in _run
    self._checkpoint_connector._restore_modules_and_callbacks(ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 396, in _restore_modules_and_callbacks
    self.restore_model()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 278, in restore_model
    trainer.strategy.load_model_state_dict(self._loaded_checkpoint)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 352, in load_model_state_dict
    self.lightning_module.load_state_dict(checkpoint["state_dict"])
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2041, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for LatentDiffusion:
	Unexpected key(s) in state_dict: "denoiser_ema.time_embed0weight", "denoiser_ema.time_embed0bias", "denoiser_ema.time_embed2weight", "denoiser_ema.time_embed2bias", "denoiser_ema.output_blocks00in_layers2weight", "denoiser_ema.output_blocks00in_layers2bias", "denoiser_ema.output_blocks00emb_layers1weight", "denoiser_ema.output_blocks00emb_layers1bias", "denoiser_ema.output_blocks00out_layers3weight", "denoiser_ema.output_blocks00out_layers3bias", "denoiser_ema.output_blocks00skip_connectionweight", "denoiser_ema.output_blocks00skip_connectionbias", "denoiser_ema.output_blocks10in_layers2weight", "denoiser_ema.output_blocks10in_layers2bias", "denoiser_ema.output_blocks10emb_layers1weight", "denoiser_ema.output_blocks10emb_layers1bias", "denoiser_ema.output_blocks10out_layers3weight", "denoiser_ema.output_blocks10out_layers3bias", "denoiser_ema.output_blocks10skip_connectionweight", "denoiser_ema.output_blocks10skip_connectionbias", "denoiser_ema.output_blocks20in_layers2weight", "denoiser_ema.output_blocks20in_layers2bias", "denoiser_ema.output_blocks20emb_layers1weight", "denoiser_ema.output_blocks20emb_layers1bias", "denoiser_ema.output_blocks20out_layers3weight", "denoiser_ema.output_blocks20out_layers3bias", "denoiser_ema.output_blocks20skip_connectionweight", "denoiser_ema.output_blocks20skip_connectionbias", "denoiser_ema.output_blocks21convweight", "denoiser_ema.output_blocks21convbias", "denoiser_ema.output_blocks30in_layers2weight", "denoiser_ema.output_blocks30in_layers2bias", "denoiser_ema.output_blocks30emb_layers1weight", "denoiser_ema.output_blocks30emb_layers1bias", "denoiser_ema.output_blocks30out_layers3weight", "denoiser_ema.output_blocks30out_layers3bias", "denoiser_ema.output_blocks30skip_connectionweight", "denoiser_ema.output_blocks30skip_connectionbias", "denoiser_ema.output_blocks31pre_projweight", "denoiser_ema.output_blocks31pre_projbias", "denoiser_ema.output_blocks31filterw1", "denoiser_ema.output_blocks31filterb1", "denoiser_ema.output_blocks31filterw2", "denoiser_ema.output_blocks31filterb2", "denoiser_ema.output_blocks31mlpfc1weight", "denoiser_ema.output_blocks31mlpfc1bias", "denoiser_ema.output_blocks31mlpfc2weight", "denoiser_ema.output_blocks31mlpfc2bias", "denoiser_ema.output_blocks40in_layers2weight", "denoiser_ema.output_blocks40in_layers2bias", "denoiser_ema.output_blocks40emb_layers1weight", "denoiser_ema.output_blocks40emb_layers1bias", "denoiser_ema.output_blocks40out_layers3weight", "denoiser_ema.output_blocks40out_layers3bias", "denoiser_ema.output_blocks40skip_connectionweight", "denoiser_ema.output_blocks40skip_connectionbias", "denoiser_ema.output_blocks41pre_projweight", "denoiser_ema.output_blocks41pre_projbias", "denoiser_ema.output_blocks41filterw1", "denoiser_ema.output_blocks41filterb1", "denoiser_ema.output_blocks41filterw2", "denoiser_ema.output_blocks41filterb2", "denoiser_ema.output_blocks41mlpfc1weight", "denoiser_ema.output_blocks41mlpfc1bias", "denoiser_ema.output_blocks41mlpfc2weight", "denoiser_ema.output_blocks41mlpfc2bias", "denoiser_ema.output_blocks50in_layers2weight", "denoiser_ema.output_blocks50in_layers2bias", "denoiser_ema.output_blocks50emb_layers1weight", "denoiser_ema.output_blocks50emb_layers1bias", "denoiser_ema.output_blocks50out_layers3weight", "denoiser_ema.output_blocks50out_layers3bias", "denoiser_ema.output_blocks50skip_connectionweight", "denoiser_ema.output_blocks50skip_connectionbias", "denoiser_ema.output_blocks51pre_projweight", "denoiser_ema.output_blocks51pre_projbias", "denoiser_ema.output_blocks51filterw1", "denoiser_ema.output_blocks51filterb1", "denoiser_ema.output_blocks51filterw2", "denoiser_ema.output_blocks51filterb2", "denoiser_ema.output_blocks51mlpfc1weight", "denoiser_ema.output_blocks51mlpfc1bias", "denoiser_ema.output_blocks51mlpfc2weight", "denoiser_ema.output_blocks51mlpfc2bias", "denoiser_ema.output_blocks52convweight", "denoiser_ema.output_blocks52convbias", "denoiser_ema.output_blocks60in_layers2weight", "denoiser_ema.output_blocks60in_layers2bias", "denoiser_ema.output_blocks60emb_layers1weight", "denoiser_ema.output_blocks60emb_layers1bias", "denoiser_ema.output_blocks60out_layers3weight", "denoiser_ema.output_blocks60out_layers3bias", "denoiser_ema.output_blocks60skip_connectionweight", "denoiser_ema.output_blocks60skip_connectionbias", "denoiser_ema.output_blocks61pre_projweight", "denoiser_ema.output_blocks61pre_projbias", "denoiser_ema.output_blocks61filterw1", "denoiser_ema.output_blocks61filterb1", "denoiser_ema.output_blocks61filterw2", "denoiser_ema.output_blocks61filterb2", "denoiser_ema.output_blocks61mlpfc1weight", "denoiser_ema.output_blocks61mlpfc1bias", "denoiser_ema.output_blocks61mlpfc2weight", "denoiser_ema.output_blocks61mlpfc2bias", "denoiser_ema.output_blocks70in_layers2weight", "denoiser_ema.output_blocks70in_layers2bias", "denoiser_ema.output_blocks70emb_layers1weight", "denoiser_ema.output_blocks70emb_layers1bias", "denoiser_ema.output_blocks70out_layers3weight", "denoiser_ema.output_blocks70out_layers3bias", "denoiser_ema.output_blocks70skip_connectionweight", "denoiser_ema.output_blocks70skip_connectionbias", "denoiser_ema.output_blocks71pre_projweight", "denoiser_ema.output_blocks71pre_projbias", "denoiser_ema.output_blocks71filterw1", "denoiser_ema.output_blocks71filterb1", "denoiser_ema.output_blocks71filterw2", "denoiser_ema.output_blocks71filterb2", "denoiser_ema.output_blocks71mlpfc1weight", "denoiser_ema.output_blocks71mlpfc1bias", "denoiser_ema.output_blocks71mlpfc2weight", "denoiser_ema.output_blocks71mlpfc2bias", "denoiser_ema.output_blocks80in_layers2weight", "denoiser_ema.output_blocks80in_layers2bias", "denoiser_ema.output_blocks80emb_layers1weight", "denoiser_ema.output_blocks80emb_layers1bias", "denoiser_ema.output_blocks80out_layers3weight", "denoiser_ema.output_blocks80out_layers3bias", "denoiser_ema.output_blocks80skip_connectionweight", "denoiser_ema.output_blocks80skip_connectionbias", "denoiser_ema.output_blocks81pre_projweight", "denoiser_ema.output_blocks81pre_projbias", "denoiser_ema.output_blocks81filterw1", "denoiser_ema.output_blocks81filterb1", "denoiser_ema.output_blocks81filterw2", "denoiser_ema.output_blocks81filterb2", "denoiser_ema.output_blocks81mlpfc1weight", "denoiser_ema.output_blocks81mlpfc1bias", "denoiser_ema.output_blocks81mlpfc2weight", "denoiser_ema.output_blocks81mlpfc2bias", "denoiser_ema.out2weight", "denoiser_ema.out2bias". 
[2025-03-26 01:50:56,243][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_01-50-06
[2025-03-26 01:53:17,655][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 01:53:17,663][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 01:53:17,781][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 01:53:17,979][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 01:53:17,980][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 01:53:18,867][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 01:53:22,480][__main__][INFO] - Instantiating callbacks...
[2025-03-26 01:53:22,487][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 01:53:22,493][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 01:53:22,494][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 01:53:22,495][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 01:53:22,496][__main__][INFO] - Instantiating loggers...
[2025-03-26 01:53:22,496][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 01:53:22,499][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 01:53:23,687][__main__][INFO] - Logging hyperparameters!
[2025-03-26 01:53:29,550][__main__][INFO] - Starting training!
[2025-03-26 01:53:53,728][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 01:53:53,729][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 01:54:04,268][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 87, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 939, in _run
    self._checkpoint_connector._restore_modules_and_callbacks(ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 396, in _restore_modules_and_callbacks
    self.restore_model()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 278, in restore_model
    trainer.strategy.load_model_state_dict(self._loaded_checkpoint)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 352, in load_model_state_dict
    self.lightning_module.load_state_dict(checkpoint["state_dict"])
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 316, in load_state_dict
    return super().load_state_dict(filtered_state_dict, strict=strict)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2041, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for LatentDiffusion:
	Missing key(s) in state_dict: "denoiser_ema.decay", "denoiser_ema.num_updates", "denoiser_ema.input_blocks00weight", "denoiser_ema.input_blocks00bias", "denoiser_ema.input_blocks10in_layers2weight", "denoiser_ema.input_blocks10in_layers2bias", "denoiser_ema.input_blocks10emb_layers1weight", "denoiser_ema.input_blocks10emb_layers1bias", "denoiser_ema.input_blocks10out_layers3weight", "denoiser_ema.input_blocks10out_layers3bias", "denoiser_ema.input_blocks11pre_projweight", "denoiser_ema.input_blocks11pre_projbias", "denoiser_ema.input_blocks11filterw1", "denoiser_ema.input_blocks11filterb1", "denoiser_ema.input_blocks11filterw2", "denoiser_ema.input_blocks11filterb2", "denoiser_ema.input_blocks11mlpfc1weight", "denoiser_ema.input_blocks11mlpfc1bias", "denoiser_ema.input_blocks11mlpfc2weight", "denoiser_ema.input_blocks11mlpfc2bias", "denoiser_ema.input_blocks20in_layers2weight", "denoiser_ema.input_blocks20in_layers2bias", "denoiser_ema.input_blocks20emb_layers1weight", "denoiser_ema.input_blocks20emb_layers1bias", "denoiser_ema.input_blocks20out_layers3weight", "denoiser_ema.input_blocks20out_layers3bias", "denoiser_ema.input_blocks21pre_projweight", "denoiser_ema.input_blocks21pre_projbias", "denoiser_ema.input_blocks21filterw1", "denoiser_ema.input_blocks21filterb1", "denoiser_ema.input_blocks21filterw2", "denoiser_ema.input_blocks21filterb2", "denoiser_ema.input_blocks21mlpfc1weight", "denoiser_ema.input_blocks21mlpfc1bias", "denoiser_ema.input_blocks21mlpfc2weight", "denoiser_ema.input_blocks21mlpfc2bias", "denoiser_ema.input_blocks30opweight", "denoiser_ema.input_blocks30opbias", "denoiser_ema.input_blocks40in_layers2weight", "denoiser_ema.input_blocks40in_layers2bias", "denoiser_ema.input_blocks40emb_layers1weight", "denoiser_ema.input_blocks40emb_layers1bias", "denoiser_ema.input_blocks40out_layers3weight", "denoiser_ema.input_blocks40out_layers3bias", "denoiser_ema.input_blocks40skip_connectionweight", "denoiser_ema.input_blocks40skip_connectionbias", "denoiser_ema.input_blocks41pre_projweight", "denoiser_ema.input_blocks41pre_projbias", "denoiser_ema.input_blocks41filterw1", "denoiser_ema.input_blocks41filterb1", "denoiser_ema.input_blocks41filterw2", "denoiser_ema.input_blocks41filterb2", "denoiser_ema.input_blocks41mlpfc1weight", "denoiser_ema.input_blocks41mlpfc1bias", "denoiser_ema.input_blocks41mlpfc2weight", "denoiser_ema.input_blocks41mlpfc2bias", "denoiser_ema.input_blocks50in_layers2weight", "denoiser_ema.input_blocks50in_layers2bias", "denoiser_ema.input_blocks50emb_layers1weight", "denoiser_ema.input_blocks50emb_layers1bias", "denoiser_ema.input_blocks50out_layers3weight", "denoiser_ema.input_blocks50out_layers3bias", "denoiser_ema.input_blocks51pre_projweight", "denoiser_ema.input_blocks51pre_projbias", "denoiser_ema.input_blocks51filterw1", "denoiser_ema.input_blocks51filterb1", "denoiser_ema.input_blocks51filterw2", "denoiser_ema.input_blocks51filterb2", "denoiser_ema.input_blocks51mlpfc1weight", "denoiser_ema.input_blocks51mlpfc1bias", "denoiser_ema.input_blocks51mlpfc2weight", "denoiser_ema.input_blocks51mlpfc2bias", "denoiser_ema.input_blocks60opweight", "denoiser_ema.input_blocks60opbias", "denoiser_ema.input_blocks70in_layers2weight", "denoiser_ema.input_blocks70in_layers2bias", "denoiser_ema.input_blocks70emb_layers1weight", "denoiser_ema.input_blocks70emb_layers1bias", "denoiser_ema.input_blocks70out_layers3weight", "denoiser_ema.input_blocks70out_layers3bias", "denoiser_ema.input_blocks70skip_connectionweight", "denoiser_ema.input_blocks70skip_connectionbias", "denoiser_ema.input_blocks80in_layers2weight", "denoiser_ema.input_blocks80in_layers2bias", "denoiser_ema.input_blocks80emb_layers1weight", "denoiser_ema.input_blocks80emb_layers1bias", "denoiser_ema.input_blocks80out_layers3weight", "denoiser_ema.input_blocks80out_layers3bias", "denoiser_ema.middle_block0in_layers2weight", "denoiser_ema.middle_block0in_layers2bias", "denoiser_ema.middle_block0emb_layers1weight", "denoiser_ema.middle_block0emb_layers1bias", "denoiser_ema.middle_block0out_layers3weight", "denoiser_ema.middle_block0out_layers3bias", "denoiser_ema.middle_block1pre_projweight", "denoiser_ema.middle_block1pre_projbias", "denoiser_ema.middle_block1filterw1", "denoiser_ema.middle_block1filterb1", "denoiser_ema.middle_block1filterw2", "denoiser_ema.middle_block1filterb2", "denoiser_ema.middle_block1mlpfc1weight", "denoiser_ema.middle_block1mlpfc1bias", "denoiser_ema.middle_block1mlpfc2weight", "denoiser_ema.middle_block1mlpfc2bias", "denoiser_ema.middle_block2in_layers2weight", "denoiser_ema.middle_block2in_layers2bias", "denoiser_ema.middle_block2emb_layers1weight", "denoiser_ema.middle_block2emb_layers1bias", "denoiser_ema.middle_block2out_layers3weight", "denoiser_ema.middle_block2out_layers3bias". 
[2025-03-26 01:54:04,289][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_01-53-17
[2025-03-26 01:56:12,178][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 01:56:12,185][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 01:56:12,270][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 01:56:12,489][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 01:56:12,490][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 01:56:13,401][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 01:56:16,904][__main__][INFO] - Instantiating callbacks...
[2025-03-26 01:56:16,904][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 01:56:16,909][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 01:56:16,910][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 01:56:16,911][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 01:56:16,912][__main__][INFO] - Instantiating loggers...
[2025-03-26 01:56:16,912][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 01:56:16,915][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 01:56:18,170][__main__][INFO] - Logging hyperparameters!
[2025-03-26 01:56:24,968][__main__][INFO] - Starting training!
[2025-03-26 01:56:50,238][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 01:56:50,238][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 01:57:11,888][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 87, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get("ckpt_path"))
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 964, in _run
    self._checkpoint_connector.restore_training_state()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 297, in restore_training_state
    self.restore_optimizers_and_schedulers()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 366, in restore_optimizers_and_schedulers
    self.restore_optimizers()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 381, in restore_optimizers
    self.trainer.strategy.load_optimizer_state_dict(self._loaded_checkpoint)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 357, in load_optimizer_state_dict
    optimizer.load_state_dict(opt_state)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 390, in load_state_dict
    raise ValueError("loaded state dict contains a parameter group "
ValueError: loaded state dict contains a parameter group that doesn't match the size of optimizer's group
[2025-03-26 01:57:11,892][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_01-56-12
[2025-03-26 02:07:06,078][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 02:07:06,085][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 02:07:06,205][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 02:07:06,416][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 02:07:06,416][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 02:07:07,104][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 02:07:10,638][__main__][INFO] - Instantiating callbacks...
[2025-03-26 02:07:10,638][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 02:07:10,643][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 02:07:10,644][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 02:07:10,645][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 02:07:10,645][__main__][INFO] - Instantiating loggers...
[2025-03-26 02:07:10,646][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 02:07:10,648][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 02:07:11,885][__main__][INFO] - Logging hyperparameters!
[2025-03-26 02:07:18,067][__main__][INFO] - Starting training!
[2025-03-26 02:07:43,365][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 02:07:43,365][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 02:08:05,398][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 67, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 964, in _run
    self._checkpoint_connector.restore_training_state()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 297, in restore_training_state
    self.restore_optimizers_and_schedulers()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 366, in restore_optimizers_and_schedulers
    self.restore_optimizers()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 381, in restore_optimizers
    self.trainer.strategy.load_optimizer_state_dict(self._loaded_checkpoint)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 357, in load_optimizer_state_dict
    optimizer.load_state_dict(opt_state)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 390, in load_state_dict
    raise ValueError("loaded state dict contains a parameter group "
ValueError: loaded state dict contains a parameter group that doesn't match the size of optimizer's group
[2025-03-26 02:08:05,403][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_02-07-05
[2025-03-26 02:11:12,627][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 02:11:12,633][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 02:11:12,750][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 02:11:12,995][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 02:11:12,995][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 02:11:13,904][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 02:11:17,509][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-03-26 02:11:20,366][__main__][INFO] - Instantiating callbacks...
[2025-03-26 02:11:20,366][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 02:11:20,370][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 02:11:20,371][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 02:11:20,372][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 02:11:20,372][__main__][INFO] - Instantiating loggers...
[2025-03-26 02:11:20,373][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 02:11:20,374][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 02:11:21,596][__main__][INFO] - Logging hyperparameters!
[2025-03-26 02:11:26,959][__main__][INFO] - Starting training!
[2025-03-26 02:11:56,460][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 02:11:56,461][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 10:16:56,540][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 10:16:56,548][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 10:16:56,650][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 10:16:57,202][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 10:16:57,202][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 10:16:58,388][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 10:17:03,698][__main__][INFO] - Instantiating callbacks...
[2025-03-26 10:17:03,699][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 10:17:03,705][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 10:17:03,707][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 10:17:03,707][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 10:17:03,708][__main__][INFO] - Instantiating loggers...
[2025-03-26 10:17:03,708][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 10:17:03,710][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 10:17:05,061][__main__][INFO] - Logging hyperparameters!
[2025-03-26 10:17:15,190][__main__][INFO] - Starting training!
[2025-03-26 10:17:39,072][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 10:17:39,073][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 10:18:21,374][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 65, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 964, in _run
    self._checkpoint_connector.restore_training_state()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 297, in restore_training_state
    self.restore_optimizers_and_schedulers()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 366, in restore_optimizers_and_schedulers
    self.restore_optimizers()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 381, in restore_optimizers
    self.trainer.strategy.load_optimizer_state_dict(self._loaded_checkpoint)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 357, in load_optimizer_state_dict
    optimizer.load_state_dict(opt_state)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 390, in load_state_dict
    raise ValueError("loaded state dict contains a parameter group "
ValueError: loaded state dict contains a parameter group that doesn't match the size of optimizer's group
[2025-03-26 10:18:21,383][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_10-16-56
[2025-03-26 10:20:02,678][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 10:20:02,685][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 10:20:02,797][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 10:20:03,028][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 10:20:03,029][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 10:20:03,888][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 10:20:07,222][__main__][INFO] - Instantiating callbacks...
[2025-03-26 10:20:07,223][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 10:20:07,227][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 10:20:07,229][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 10:20:07,229][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 10:20:07,230][__main__][INFO] - Instantiating loggers...
[2025-03-26 10:20:07,230][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 10:20:07,233][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 10:20:08,550][__main__][INFO] - Logging hyperparameters!
[2025-03-26 10:20:14,746][__main__][INFO] - Starting training!
[2025-03-26 10:20:38,629][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 10:20:38,629][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 11:48:48,862][__main__][INFO] - Starting testing!
[2025-03-26 11:52:33,664][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 11:52:33,671][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 11:52:33,878][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 11:52:34,063][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 11:52:34,063][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 11:52:34,843][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 11:52:45,291][__main__][INFO] - Instantiating callbacks...
[2025-03-26 11:52:45,292][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 11:52:45,295][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 11:52:45,296][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 11:52:45,297][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 11:52:45,297][__main__][INFO] - Instantiating loggers...
[2025-03-26 11:52:45,298][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 11:52:45,299][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 11:52:46,758][__main__][INFO] - Logging hyperparameters!
[2025-03-26 11:52:48,648][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_11-52-33
[2025-03-26 11:53:25,190][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 11:53:25,197][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 11:53:25,281][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 11:53:25,442][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 11:53:25,442][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 11:53:26,132][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 11:53:29,623][__main__][INFO] - Instantiating callbacks...
[2025-03-26 11:53:29,624][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 11:53:29,629][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 11:53:29,630][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 11:53:29,631][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 11:53:29,632][__main__][INFO] - Instantiating loggers...
[2025-03-26 11:53:29,632][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 11:53:29,635][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 11:53:31,127][__main__][INFO] - Logging hyperparameters!
[2025-03-26 11:53:36,450][__main__][INFO] - Starting training!
[2025-03-26 11:54:02,791][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 11:54:02,792][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 12:04:53,370][__main__][INFO] - Starting testing!
[2025-03-26 12:04:53,379][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-03-26 12:04:53,942][__main__][INFO] - Best ckpt path: None
[2025-03-26 12:04:53,944][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_11-53-25
[2025-03-26 12:05:45,052][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 12:05:45,059][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 12:05:45,143][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 12:05:45,408][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 12:05:45,408][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 12:05:46,301][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 12:05:49,860][__main__][INFO] - Instantiating callbacks...
[2025-03-26 12:05:49,861][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 12:05:49,865][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 12:05:49,866][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 12:05:49,867][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 12:05:49,868][__main__][INFO] - Instantiating loggers...
[2025-03-26 12:05:49,868][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 12:05:49,871][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 12:05:51,122][__main__][INFO] - Logging hyperparameters!
[2025-03-26 12:05:57,088][__main__][INFO] - Starting training!
[2025-03-26 12:06:22,121][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 12:06:22,122][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 12:07:05,208][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 65, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 964, in _run
    self._checkpoint_connector.restore_training_state()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 297, in restore_training_state
    self.restore_optimizers_and_schedulers()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 366, in restore_optimizers_and_schedulers
    self.restore_optimizers()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 381, in restore_optimizers
    self.trainer.strategy.load_optimizer_state_dict(self._loaded_checkpoint)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 357, in load_optimizer_state_dict
    optimizer.load_state_dict(opt_state)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 390, in load_state_dict
    raise ValueError("loaded state dict contains a parameter group "
ValueError: loaded state dict contains a parameter group that doesn't match the size of optimizer's group
[2025-03-26 12:07:05,214][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_12-05-44
[2025-03-26 13:16:47,544][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 13:16:47,552][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 13:16:47,665][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 13:16:48,437][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 13:16:48,437][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 13:16:49,457][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 13:16:54,962][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-03-26 13:17:13,544][__main__][INFO] - Instantiating callbacks...
[2025-03-26 13:17:13,546][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 13:17:13,553][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 13:17:13,554][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 13:17:13,555][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 13:17:13,555][__main__][INFO] - Instantiating loggers...
[2025-03-26 13:17:13,556][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 13:17:13,558][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 13:17:15,304][__main__][INFO] - Logging hyperparameters!
[2025-03-26 13:17:26,084][__main__][INFO] - Starting training!
[2025-03-26 13:17:58,215][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 13:17:58,216][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 13:43:05,305][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 13:43:05,313][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 13:43:05,397][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 13:43:05,632][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 13:43:05,632][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 13:43:06,231][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 13:43:09,937][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-03-26 13:43:13,295][__main__][INFO] - Instantiating callbacks...
[2025-03-26 13:43:13,296][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 13:43:13,301][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 13:43:13,302][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 13:43:13,303][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 13:43:13,303][__main__][INFO] - Instantiating loggers...
[2025-03-26 13:43:13,304][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 13:43:13,306][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 13:43:14,971][__main__][INFO] - Logging hyperparameters!
[2025-03-26 13:43:20,551][__main__][INFO] - Starting training!
[2025-03-26 13:43:51,748][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 13:43:51,748][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 13:55:14,056][__main__][INFO] - Starting testing!
[2025-03-26 13:55:14,070][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-03-26 13:55:15,704][__main__][INFO] - Best ckpt path: None
[2025-03-26 13:55:15,708][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_13-43-05
[2025-03-26 13:55:52,759][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 13:55:52,773][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 13:55:52,874][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 13:55:53,041][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 13:55:53,042][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 13:55:53,670][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 13:55:57,092][__main__][INFO] - Instantiating callbacks...
[2025-03-26 13:55:57,093][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 13:55:57,098][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 13:55:57,099][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 13:55:57,100][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 13:55:57,101][__main__][INFO] - Instantiating loggers...
[2025-03-26 13:55:57,101][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 13:55:57,104][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 13:55:58,804][__main__][INFO] - Logging hyperparameters!
[2025-03-26 13:56:03,946][__main__][INFO] - Starting training!
[2025-03-26 13:56:27,064][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 13:56:27,064][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 13:56:49,631][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 65, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 964, in _run
    self._checkpoint_connector.restore_training_state()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 297, in restore_training_state
    self.restore_optimizers_and_schedulers()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 366, in restore_optimizers_and_schedulers
    self.restore_optimizers()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py", line 381, in restore_optimizers
    self.trainer.strategy.load_optimizer_state_dict(self._loaded_checkpoint)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 357, in load_optimizer_state_dict
    optimizer.load_state_dict(opt_state)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 390, in load_state_dict
    raise ValueError("loaded state dict contains a parameter group "
ValueError: loaded state dict contains a parameter group that doesn't match the size of optimizer's group
[2025-03-26 13:56:49,636][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_13-55-52
[2025-03-26 14:02:59,635][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 14:02:59,642][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 14:02:59,730][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 14:02:59,987][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 14:02:59,987][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 14:03:00,659][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 14:03:04,265][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_UV.ckpt without optimizer state.
[2025-03-26 14:03:07,795][__main__][INFO] - Instantiating callbacks...
[2025-03-26 14:03:07,796][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 14:03:07,800][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 14:03:07,801][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 14:03:07,802][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 14:03:07,803][__main__][INFO] - Instantiating loggers...
[2025-03-26 14:03:07,804][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 14:03:07,806][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 14:03:09,382][__main__][INFO] - Logging hyperparameters!
[2025-03-26 14:03:14,747][__main__][INFO] - Starting training!
[2025-03-26 14:03:44,636][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 14:03:44,636][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 14:14:22,290][__main__][INFO] - Starting testing!
[2025-03-26 14:14:22,298][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-03-26 14:26:50,909][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 14:26:50,916][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 14:26:51,000][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 14:26:51,228][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 14:26:51,228][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 14:26:51,844][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 14:26:55,468][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_UV.ckpt without optimizer state.
[2025-03-26 14:26:58,836][__main__][INFO] - Instantiating callbacks...
[2025-03-26 14:26:58,837][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 14:26:58,841][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 14:26:58,842][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 14:26:58,843][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 14:26:58,843][__main__][INFO] - Instantiating loggers...
[2025-03-26 14:26:58,843][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 14:26:58,845][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 14:27:00,573][__main__][INFO] - Logging hyperparameters!
[2025-03-26 14:27:06,166][__main__][INFO] - Starting training!
[2025-03-26 14:27:36,579][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 14:27:36,580][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 17:10:24,667][__main__][INFO] - Starting testing!
[2025-03-26 17:18:15,048][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 17:18:15,053][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 17:18:15,121][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 17:18:15,268][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 17:18:15,269][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 17:18:15,647][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 17:18:17,309][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_17-18-14
[2025-03-26 17:18:42,354][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 17:18:42,362][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 17:18:42,469][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 17:18:42,595][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 17:18:42,595][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 17:18:42,953][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 17:18:54,132][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_UV copy.ckpt without optimizer state.
[2025-03-26 17:19:12,381][__main__][INFO] - Instantiating callbacks...
[2025-03-26 17:19:12,382][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 17:19:12,386][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 17:19:12,387][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 17:19:12,388][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 17:19:12,390][__main__][INFO] - Instantiating loggers...
[2025-03-26 17:19:12,391][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 17:19:12,393][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 17:19:14,104][__main__][INFO] - Logging hyperparameters!
[2025-03-26 17:19:19,785][__main__][INFO] - Starting training!
[2025-03-26 17:19:52,219][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 17:19:52,220][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 17:45:44,546][__main__][INFO] - Starting testing!
[2025-03-26 17:50:16,482][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_17-18-42/checkpoints/epoch_000.ckpt
[2025-03-26 17:50:16,715][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_17-18-42
[2025-03-26 17:50:16,715][src.utils.utils][INFO] - Retrieved metric value! <val/loss=nan>
[2025-03-26 18:39:44,626][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 18:39:44,633][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 18:39:44,725][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 18:39:44,976][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 18:39:44,977][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 18:39:45,690][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 18:39:50,998][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_UV copy.ckpt without optimizer state.
[2025-03-26 18:41:01,158][__main__][INFO] - Instantiating callbacks...
[2025-03-26 18:41:01,160][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 18:41:01,164][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 18:41:01,165][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 18:41:01,166][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 18:41:01,168][__main__][INFO] - Instantiating loggers...
[2025-03-26 18:41:01,168][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 18:41:01,170][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 18:41:02,973][__main__][INFO] - Logging hyperparameters!
[2025-03-26 18:41:07,912][__main__][INFO] - Starting training!
[2025-03-26 18:41:40,271][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 18:41:40,272][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 18:44:25,402][__main__][INFO] - Starting testing!
[2025-03-26 18:44:25,404][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-03-26 18:44:25,534][__main__][INFO] - Best ckpt path: None
[2025-03-26 18:44:26,352][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_18-39-44
[2025-03-26 18:44:47,375][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 18:44:47,385][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 18:44:47,612][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 18:44:47,819][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 18:44:47,820][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 18:44:48,423][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 18:45:00,398][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_UV copy.ckpt without optimizer state.
[2025-03-26 18:45:08,486][__main__][INFO] - Instantiating callbacks...
[2025-03-26 18:45:08,487][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 18:45:08,497][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 18:45:08,498][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 18:45:08,499][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 18:45:08,514][__main__][INFO] - Instantiating loggers...
[2025-03-26 18:45:08,514][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 18:45:08,516][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 18:45:10,605][__main__][INFO] - Logging hyperparameters!
[2025-03-26 18:45:15,396][__main__][INFO] - Starting training!
[2025-03-26 18:46:12,570][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 18:46:12,570][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 18:47:53,750][__main__][INFO] - Starting testing!
[2025-03-26 18:47:53,767][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-03-26 18:48:29,675][__main__][INFO] - Best ckpt path: None
[2025-03-26 18:48:30,551][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_18-44-47
[2025-03-26 19:03:42,990][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 19:03:42,999][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 19:03:43,209][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 19:03:43,496][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 19:03:43,496][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 19:03:44,112][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 19:04:02,806][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_UV copy.ckpt without optimizer state.
[2025-03-26 19:04:38,742][__main__][INFO] - Instantiating callbacks...
[2025-03-26 19:04:38,743][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 19:04:38,753][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 19:04:38,765][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 19:04:38,765][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 19:04:38,767][__main__][INFO] - Instantiating loggers...
[2025-03-26 19:04:38,768][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 19:04:38,770][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 19:04:40,970][__main__][INFO] - Logging hyperparameters!
[2025-03-26 19:04:46,994][__main__][INFO] - Starting training!
[2025-03-26 19:05:51,660][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 19:05:51,660][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 19:07:51,600][__main__][INFO] - Starting testing!
[2025-03-26 19:07:51,630][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-03-26 19:10:13,066][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 19:10:13,077][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 19:10:13,169][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 19:10:13,415][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 19:10:13,415][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 19:10:14,181][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 19:10:18,071][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_UV copy.ckpt without optimizer state.
[2025-03-26 19:10:21,723][__main__][INFO] - Instantiating callbacks...
[2025-03-26 19:10:21,724][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 19:10:21,728][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 19:10:21,729][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 19:10:21,730][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 19:10:21,731][__main__][INFO] - Instantiating loggers...
[2025-03-26 19:10:21,731][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 19:10:21,733][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 19:10:23,723][__main__][INFO] - Logging hyperparameters!
[2025-03-26 19:10:30,754][__main__][INFO] - Starting training!
[2025-03-26 19:11:02,939][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 19:11:02,939][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 19:11:42,625][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 65, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1014, in _run_stage
    self._run_sanity_check()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1043, in _run_sanity_check
    val_loop.run()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 115, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 375, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_kwargs.values())
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 336, in validation_step
    return self.model(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/overrides/base.py", line 102, in forward
    return self._forward_module.validation_step(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 291, in validation_step
    loss = self.shared_step(batch)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 282, in shared_step
    return self(y, context=context)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 268, in forward
    return self.p_losses(x, t, *args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 247, in p_losses
    print("wind_field has NaN:", torch.isnan(wind_field).any().item())
UnboundLocalError: local variable 'wind_field' referenced before assignment
[2025-03-26 19:11:42,642][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_19-10-12
[2025-03-26 19:15:37,064][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 19:15:37,074][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 19:15:37,165][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 19:15:37,414][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 19:15:37,414][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 19:15:38,121][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 19:15:41,851][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_UV copy.ckpt without optimizer state.
[2025-03-26 19:15:45,439][__main__][INFO] - Instantiating callbacks...
[2025-03-26 19:15:45,442][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 19:15:45,445][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 19:15:45,447][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 19:15:45,447][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 19:15:45,448][__main__][INFO] - Instantiating loggers...
[2025-03-26 19:15:45,448][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 19:15:45,450][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 19:15:47,252][__main__][INFO] - Logging hyperparameters!
[2025-03-26 19:15:53,707][__main__][INFO] - Starting training!
[2025-03-26 19:16:25,548][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 19:16:25,548][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 19:21:22,553][__main__][INFO] - Starting testing!
[2025-03-26 19:21:22,555][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-03-26 19:21:38,785][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1132, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/usr/lib/python3.10/queue.py", line 179, in get
    raise Empty
_queue.Empty

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 75, in train
    trainer.test(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 735, in test
    return call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 778, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1009, in _run_stage
    return self._evaluation_loop.run()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 108, in run
    batch, batch_idx, dataloader_idx = next(data_fetcher)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py", line 136, in __next__
    self._fetch_next_batch(self.dataloader_iter)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/fetchers.py", line 150, in _fetch_next_batch
    batch = next(iterator)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py", line 284, in __next__
    out = next(self._iterator)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/utilities/combined_loader.py", line 123, in __next__
    out = next(self.iterators[0])
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1328, in _next_data
    idx, data = self._get_data()
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1284, in _get_data
    success, data = self._try_get_data()
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1145, in _try_get_data
    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 3991173, 3991181, 3991198, 3991229, 3991264, 3991273, 3991285) exited unexpectedly
[2025-03-26 19:21:38,792][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_19-15-36
[2025-03-26 19:22:49,410][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 19:22:49,416][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 19:22:49,508][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 19:22:49,767][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 19:22:49,768][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 19:22:50,547][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 19:22:55,929][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT copy.ckpt without optimizer state.
[2025-03-26 19:23:16,493][__main__][INFO] - Instantiating callbacks...
[2025-03-26 19:23:16,494][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 19:23:16,498][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 19:23:16,499][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 19:23:16,500][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 19:23:16,501][__main__][INFO] - Instantiating loggers...
[2025-03-26 19:23:16,501][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 19:23:16,503][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 19:23:18,373][__main__][INFO] - Logging hyperparameters!
[2025-03-26 19:23:25,144][__main__][INFO] - Starting training!
[2025-03-26 19:23:57,550][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 19:23:57,551][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 20:00:00,029][__main__][INFO] - Starting testing!
[2025-03-26 20:03:26,114][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_19-22-49/checkpoints/epoch_001.ckpt
[2025-03-26 20:03:26,118][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_19-22-49
[2025-03-26 20:03:26,118][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.24237550795078278>
[2025-03-26 20:40:28,498][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-26 20:40:28,507][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-26 20:40:28,591][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-26 20:40:28,844][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-26 20:40:28,845][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-26 20:40:29,565][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-26 20:40:40,801][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT copy.ckpt without optimizer state.
[2025-03-26 20:41:54,207][__main__][INFO] - Instantiating callbacks...
[2025-03-26 20:41:54,208][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-26 20:41:54,213][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-26 20:41:54,214][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-26 20:41:54,215][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-26 20:41:54,218][__main__][INFO] - Instantiating loggers...
[2025-03-26 20:41:54,218][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-26 20:41:54,220][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-26 20:41:56,132][__main__][INFO] - Logging hyperparameters!
[2025-03-26 20:42:02,116][__main__][INFO] - Starting training!
[2025-03-26 20:42:35,057][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-26 20:42:35,058][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-26 23:59:10,267][__main__][INFO] - Starting testing!
[2025-03-27 00:02:36,461][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_20-40-28/checkpoints/epoch_001.ckpt
[2025-03-27 00:02:36,464][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-26_20-40-28
[2025-03-27 00:02:36,464][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.3016180992126465>
[2025-03-27 00:20:31,928][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-27 00:20:31,936][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-27 00:20:32,033][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-27 00:20:32,642][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-27 00:20:32,643][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-27 00:20:33,900][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-27 00:20:39,542][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT copy.ckpt without optimizer state.
[2025-03-27 00:20:58,182][__main__][INFO] - Instantiating callbacks...
[2025-03-27 00:20:58,183][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-27 00:20:58,190][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-27 00:20:58,191][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-27 00:20:58,191][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-27 00:20:58,193][__main__][INFO] - Instantiating loggers...
[2025-03-27 00:20:58,193][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-27 00:20:58,194][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-27 00:20:59,500][__main__][INFO] - Logging hyperparameters!
[2025-03-27 00:21:22,256][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-27 00:21:22,263][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-27 00:21:22,345][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-27 00:21:22,511][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-27 00:21:22,511][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-27 00:21:23,376][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-27 00:21:26,986][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT copy.ckpt without optimizer state.
[2025-03-27 00:21:29,833][__main__][INFO] - Instantiating callbacks...
[2025-03-27 00:21:29,833][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-27 00:21:29,837][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-27 00:21:29,838][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-27 00:21:29,838][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-27 00:21:29,839][__main__][INFO] - Instantiating loggers...
[2025-03-27 00:21:29,839][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-27 00:21:29,840][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-27 00:21:31,138][__main__][INFO] - Logging hyperparameters!
[2025-03-27 00:21:37,710][__main__][INFO] - Starting training!
[2025-03-27 00:22:07,607][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-27 00:22:07,608][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-27 05:13:04,376][__main__][INFO] - Starting testing!
[2025-03-27 05:16:30,573][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-27_00-21-22/checkpoints/epoch_012.ckpt
[2025-03-27 05:16:30,797][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-27_00-21-22
[2025-03-27 05:16:30,797][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.27894917130470276>
[2025-03-27 19:40:10,662][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-27 19:40:10,669][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-27 19:40:10,751][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-27 19:40:10,951][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-27 19:40:10,952][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-27 19:40:11,755][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-27 19:40:15,288][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT copy.ckpt without optimizer state.
[2025-03-27 19:40:32,715][__main__][INFO] - Instantiating callbacks...
[2025-03-27 19:40:32,717][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-27 19:40:32,720][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-27 19:40:32,721][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-27 19:40:32,721][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-27 19:40:32,722][__main__][INFO] - Instantiating loggers...
[2025-03-27 19:40:32,722][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-27 19:40:32,723][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-27 19:40:33,934][__main__][INFO] - Logging hyperparameters!
[2025-03-27 19:40:39,303][__main__][INFO] - Starting training!
[2025-03-27 19:41:08,407][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-27 19:41:08,408][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-27 19:43:35,649][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-27 19:43:35,657][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-27 19:43:35,762][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-27 19:43:36,383][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-27 19:43:36,384][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-27 19:43:37,582][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-27 19:43:42,867][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT copy.ckpt without optimizer state.
[2025-03-27 19:44:00,425][__main__][INFO] - Instantiating callbacks...
[2025-03-27 19:44:00,427][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-27 19:44:00,435][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-27 19:44:00,436][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-27 19:44:00,437][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-27 19:44:00,438][__main__][INFO] - Instantiating loggers...
[2025-03-27 19:44:00,438][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-27 19:44:00,440][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-27 19:44:01,825][__main__][INFO] - Logging hyperparameters!
[2025-03-27 19:44:12,598][__main__][INFO] - Starting training!
[2025-03-27 19:44:44,090][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-27 19:44:44,091][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-27 19:51:41,877][__main__][INFO] - Starting testing!
[2025-03-27 19:51:41,904][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-03-27 19:51:42,346][__main__][INFO] - Best ckpt path: None
[2025-03-27 19:51:42,948][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-27_19-43-35
[2025-03-27 19:52:16,295][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-27 19:52:16,302][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-27 19:52:16,389][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-27 19:52:16,542][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-27 19:52:16,542][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-27 19:52:17,191][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-27 19:52:20,643][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT copy.ckpt without optimizer state.
[2025-03-27 19:52:23,612][__main__][INFO] - Instantiating callbacks...
[2025-03-27 19:52:23,613][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-27 19:52:23,616][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-27 19:52:23,617][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-27 19:52:23,618][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-27 19:52:23,618][__main__][INFO] - Instantiating loggers...
[2025-03-27 19:52:23,619][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-27 19:52:23,620][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-27 19:52:24,685][__main__][INFO] - Logging hyperparameters!
[2025-03-27 19:52:28,727][__main__][INFO] - Starting training!
[2025-03-27 19:52:58,451][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-27 19:52:58,452][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-27 19:55:22,644][__main__][INFO] - Starting testing!
[2025-03-27 19:55:22,659][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-03-27 19:55:23,067][__main__][INFO] - Best ckpt path: None
[2025-03-27 19:55:23,675][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-27_19-52-16
[2025-03-27 19:56:22,437][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-27 19:56:22,444][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-27 19:56:22,530][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-27 19:56:22,690][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-27 19:56:22,690][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-27 19:56:23,333][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-27 19:56:26,826][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT copy.ckpt without optimizer state.
[2025-03-27 19:56:29,503][__main__][INFO] - Instantiating callbacks...
[2025-03-27 19:56:29,503][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-27 19:56:29,507][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-27 19:56:29,508][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-27 19:56:29,509][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-27 19:56:29,509][__main__][INFO] - Instantiating loggers...
[2025-03-27 19:56:29,510][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-27 19:56:29,511][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-27 19:56:30,563][__main__][INFO] - Logging hyperparameters!
[2025-03-27 19:56:35,096][__main__][INFO] - Starting training!
[2025-03-27 19:57:04,127][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-27 19:57:04,128][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-27 19:57:48,518][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 65, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1014, in _run_stage
    self._run_sanity_check()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1043, in _run_sanity_check
    val_loop.run()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 115, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 375, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_kwargs.values())
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 336, in validation_step
    return self.model(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/overrides/base.py", line 102, in forward
    return self._forward_module.validation_step(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 312, in validation_step
    loss = self.shared_step(batch)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 303, in shared_step
    return self(latent_target, context=context_dict)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 282, in forward
    return self.p_losses(x, t, *args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 275, in p_losses
    print("pde_loss_val" + pde_loss_val)
TypeError: can only concatenate str (not "Tensor") to str
[2025-03-27 19:57:48,555][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-27_19-56-22
[2025-03-27 20:00:12,159][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-27 20:00:12,167][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-27 20:00:12,259][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-27 20:00:12,459][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-27 20:00:12,460][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-27 20:00:13,190][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-27 20:00:16,633][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT copy.ckpt without optimizer state.
[2025-03-27 20:00:19,708][__main__][INFO] - Instantiating callbacks...
[2025-03-27 20:00:19,708][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-27 20:00:19,712][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-27 20:00:19,714][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-27 20:00:19,714][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-27 20:00:19,716][__main__][INFO] - Instantiating loggers...
[2025-03-27 20:00:19,716][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-27 20:00:19,718][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-27 20:00:21,073][__main__][INFO] - Logging hyperparameters!
[2025-03-27 20:00:26,153][__main__][INFO] - Starting training!
[2025-03-27 20:00:54,325][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-27 20:00:54,326][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-27 20:03:51,864][__main__][INFO] - Starting testing!
[2025-03-27 20:03:51,891][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-03-27 20:06:10,162][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-03-27 20:06:10,170][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-03-27 20:06:10,250][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-03-27 20:06:10,402][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-03-27 20:06:10,402][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-03-27 20:06:11,036][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-03-27 20:06:14,569][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT copy.ckpt without optimizer state.
[2025-03-27 20:06:17,373][__main__][INFO] - Instantiating callbacks...
[2025-03-27 20:06:17,373][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-03-27 20:06:17,376][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-03-27 20:06:17,377][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-03-27 20:06:17,378][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-03-27 20:06:17,378][__main__][INFO] - Instantiating loggers...
[2025-03-27 20:06:17,378][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-03-27 20:06:17,380][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-03-27 20:06:18,593][__main__][INFO] - Logging hyperparameters!
[2025-03-27 20:06:22,709][__main__][INFO] - Starting training!
[2025-03-27 20:06:51,292][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-03-27 20:06:51,292][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-03-28 00:57:09,507][__main__][INFO] - Starting testing!
[2025-03-28 01:00:36,962][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-27_20-06-10/checkpoints/epoch_012.ckpt
[2025-03-28 01:00:37,140][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-03-27_20-06-10
[2025-03-28 01:00:37,140][src.utils.utils][INFO] - Retrieved metric value! <val/loss=2.0456416606903076>
[2025-04-01 17:10:23,058][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-01 17:10:23,065][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-01 17:10:23,163][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-01 17:10:23,611][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-01 17:10:23,611][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-01 17:10:24,686][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-01 17:10:29,466][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-01 17:10:44,872][__main__][INFO] - Instantiating callbacks...
[2025-04-01 17:10:44,873][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-01 17:10:44,878][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-01 17:10:44,879][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-01 17:10:44,880][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-01 17:10:44,881][__main__][INFO] - Instantiating loggers...
[2025-04-01 17:10:44,881][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-01 17:10:44,883][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-01 17:10:46,027][__main__][INFO] - Logging hyperparameters!
[2025-04-01 17:10:55,632][__main__][INFO] - Starting training!
[2025-04-01 17:11:27,996][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-01 17:11:27,996][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-01 17:12:16,685][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 65, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1014, in _run_stage
    self._run_sanity_check()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1043, in _run_sanity_check
    val_loop.run()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 115, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 375, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_kwargs.values())
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 336, in validation_step
    return self.model(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/overrides/base.py", line 102, in forward
    return self._forward_module.validation_step(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 325, in validation_step
    self.log("val/loss", loss, **log_params, sync_dist=True)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 441, in log
    value = apply_to_collection(value, (Tensor, numbers.Number), self.__to_tensor, name)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning_utilities/core/apply_func.py", line 64, in apply_to_collection
    return function(data, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 615, in __to_tensor
    raise ValueError(
ValueError: `self.log(val/loss, tensor([[[[ 0.2195,  0.2982,  0.3717,  ...,  0.4118,  0.4388,  0.3824],
          [ 0.2094,  0.1984,  0.2398,  ...,  0.2830,  0.3298,  0.3857],
          [ 0.1702,  0.0632,  0.1131,  ...,  0.1966,  0.2563,  0.3384],
          ...,
          [ 0.2804,  0.2691,  0.2312,  ...,  0.0853,  0.0919,  0.1193],
          [ 0.3140,  0.3025,  0.2404,  ...,  0.0854,  0.0893,  0.1079],
          [ 0.3105,  0.3047,  0.2825,  ...,  0.1090,  0.1034,  0.1005]]],


        [[[-0.0225, -0.0039,  0.0139,  ...,  0.1316,  0.1103,  0.0732],
          [-0.0258,  0.0018,  0.0187,  ...,  0.0987,  0.0786,  0.0795],
          [ 0.0135,  0.0328,  0.0533,  ...,  0.0531,  0.0423,  0.0515],
          ...,
          [-0.0598, -0.0627, -0.0678,  ..., -0.1054, -0.1151, -0.0946],
          [-0.0632, -0.0692, -0.0707,  ..., -0.1054, -0.1071, -0.0789],
          [-0.0531, -0.0677, -0.0609,  ..., -0.0934, -0.0881, -0.0706]]],


        [[[-0.1486, -0.2259, -0.2914,  ..., -0.0760, -0.0549, -0.0582],
          [-0.1897, -0.2416, -0.2513,  ..., -0.1402, -0.1069, -0.0725],
          [-0.2150, -0.2463, -0.1819,  ..., -0.1456, -0.1169, -0.0823],
          ...,
          [ 0.3815,  0.3938,  0.3973,  ..., -0.1041, -0.0767, -0.0546],
          [ 0.4756,  0.5176,  0.4933,  ..., -0.1026, -0.0819, -0.0527],
          [ 0.4903,  0.5259,  0.5244,  ..., -0.0872, -0.0708, -0.0513]]],


        ...,


        [[[-0.0374, -0.0302, -0.0139,  ..., -0.0596, -0.0603, -0.0553],
          [-0.0533, -0.0618, -0.0557,  ..., -0.1040, -0.0980, -0.0699],
          [-0.0380, -0.0459, -0.0433,  ..., -0.0967, -0.0939, -0.0666],
          ...,
          [-0.0900, -0.0934, -0.1036,  ..., -0.1250, -0.1108, -0.0884],
          [-0.0875, -0.0914, -0.0959,  ..., -0.1119, -0.1021, -0.0762],
          [-0.0739, -0.0882, -0.0849,  ..., -0.1023, -0.0931, -0.0717]]],


        [[[-0.0682, -0.0533, -0.0198,  ..., -0.0062, -0.0095, -0.0157],
          [-0.0840, -0.0776, -0.0551,  ..., -0.0503, -0.0469, -0.0234],
          [-0.0661, -0.0645, -0.0497,  ..., -0.0500, -0.0430, -0.0178],
          ...,
          [-0.0623, -0.0632, -0.0697,  ..., -0.1504, -0.1547, -0.1306],
          [-0.0544, -0.0598, -0.0621,  ..., -0.1471, -0.1450, -0.1200],
          [-0.0396, -0.0561, -0.0498,  ..., -0.1443, -0.1314, -0.1124]]],


        [[[ 0.0671,  0.0663,  0.0653,  ..., -0.0149, -0.0078, -0.0134],
          [ 0.0562,  0.0505,  0.0575,  ..., -0.0615, -0.0507, -0.0283],
          [ 0.0485,  0.0383,  0.0639,  ..., -0.0503, -0.0405, -0.0216],
          ...,
          [-0.0451, -0.0402,  0.0109,  ..., -0.1304, -0.1250, -0.1108],
          [-0.1051, -0.1075, -0.0682,  ..., -0.1240, -0.1187, -0.0985],
          [-0.1062, -0.1166, -0.1083,  ..., -0.1148, -0.1074, -0.0912]]]],
       device='cuda:0'))` was called, but the tensor must have a single element. You can try doing `self.log(val/loss, tensor([[[[ 0.2195,  0.2982,  0.3717,  ...,  0.4118,  0.4388,  0.3824],
          [ 0.2094,  0.1984,  0.2398,  ...,  0.2830,  0.3298,  0.3857],
          [ 0.1702,  0.0632,  0.1131,  ...,  0.1966,  0.2563,  0.3384],
          ...,
          [ 0.2804,  0.2691,  0.2312,  ...,  0.0853,  0.0919,  0.1193],
          [ 0.3140,  0.3025,  0.2404,  ...,  0.0854,  0.0893,  0.1079],
          [ 0.3105,  0.3047,  0.2825,  ...,  0.1090,  0.1034,  0.1005]]],


        [[[-0.0225, -0.0039,  0.0139,  ...,  0.1316,  0.1103,  0.0732],
          [-0.0258,  0.0018,  0.0187,  ...,  0.0987,  0.0786,  0.0795],
          [ 0.0135,  0.0328,  0.0533,  ...,  0.0531,  0.0423,  0.0515],
          ...,
          [-0.0598, -0.0627, -0.0678,  ..., -0.1054, -0.1151, -0.0946],
          [-0.0632, -0.0692, -0.0707,  ..., -0.1054, -0.1071, -0.0789],
          [-0.0531, -0.0677, -0.0609,  ..., -0.0934, -0.0881, -0.0706]]],


        [[[-0.1486, -0.2259, -0.2914,  ..., -0.0760, -0.0549, -0.0582],
          [-0.1897, -0.2416, -0.2513,  ..., -0.1402, -0.1069, -0.0725],
          [-0.2150, -0.2463, -0.1819,  ..., -0.1456, -0.1169, -0.0823],
          ...,
          [ 0.3815,  0.3938,  0.3973,  ..., -0.1041, -0.0767, -0.0546],
          [ 0.4756,  0.5176,  0.4933,  ..., -0.1026, -0.0819, -0.0527],
          [ 0.4903,  0.5259,  0.5244,  ..., -0.0872, -0.0708, -0.0513]]],


        ...,


        [[[-0.0374, -0.0302, -0.0139,  ..., -0.0596, -0.0603, -0.0553],
          [-0.0533, -0.0618, -0.0557,  ..., -0.1040, -0.0980, -0.0699],
          [-0.0380, -0.0459, -0.0433,  ..., -0.0967, -0.0939, -0.0666],
          ...,
          [-0.0900, -0.0934, -0.1036,  ..., -0.1250, -0.1108, -0.0884],
          [-0.0875, -0.0914, -0.0959,  ..., -0.1119, -0.1021, -0.0762],
          [-0.0739, -0.0882, -0.0849,  ..., -0.1023, -0.0931, -0.0717]]],


        [[[-0.0682, -0.0533, -0.0198,  ..., -0.0062, -0.0095, -0.0157],
          [-0.0840, -0.0776, -0.0551,  ..., -0.0503, -0.0469, -0.0234],
          [-0.0661, -0.0645, -0.0497,  ..., -0.0500, -0.0430, -0.0178],
          ...,
          [-0.0623, -0.0632, -0.0697,  ..., -0.1504, -0.1547, -0.1306],
          [-0.0544, -0.0598, -0.0621,  ..., -0.1471, -0.1450, -0.1200],
          [-0.0396, -0.0561, -0.0498,  ..., -0.1443, -0.1314, -0.1124]]],


        [[[ 0.0671,  0.0663,  0.0653,  ..., -0.0149, -0.0078, -0.0134],
          [ 0.0562,  0.0505,  0.0575,  ..., -0.0615, -0.0507, -0.0283],
          [ 0.0485,  0.0383,  0.0639,  ..., -0.0503, -0.0405, -0.0216],
          ...,
          [-0.0451, -0.0402,  0.0109,  ..., -0.1304, -0.1250, -0.1108],
          [-0.1051, -0.1075, -0.0682,  ..., -0.1240, -0.1187, -0.0985],
          [-0.1062, -0.1166, -0.1083,  ..., -0.1148, -0.1074, -0.0912]]]],
       device='cuda:0').mean())`
[2025-04-01 17:12:16,716][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-01_17-10-22
[2025-04-01 17:26:38,183][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-01 17:26:38,190][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-01 17:26:38,275][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-01 17:26:38,492][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-01 17:26:38,492][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-01 17:26:39,401][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-01 17:26:43,064][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-01 17:26:46,383][__main__][INFO] - Instantiating callbacks...
[2025-04-01 17:26:46,384][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-01 17:26:46,389][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-01 17:26:46,390][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-01 17:26:46,391][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-01 17:26:46,391][__main__][INFO] - Instantiating loggers...
[2025-04-01 17:26:46,392][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-01 17:26:46,394][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-01 17:26:47,812][__main__][INFO] - Logging hyperparameters!
[2025-04-01 17:26:53,582][__main__][INFO] - Starting training!
[2025-04-01 17:27:26,063][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-01 17:27:26,064][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-01 17:28:13,858][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 65, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1014, in _run_stage
    self._run_sanity_check()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1043, in _run_sanity_check
    val_loop.run()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 115, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 375, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_kwargs.values())
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 336, in validation_step
    return self.model(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/overrides/base.py", line 102, in forward
    return self._forward_module.validation_step(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 325, in validation_step
    self.log("val/loss", loss, **log_params, sync_dist=True)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 441, in log
    value = apply_to_collection(value, (Tensor, numbers.Number), self.__to_tensor, name)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning_utilities/core/apply_func.py", line 64, in apply_to_collection
    return function(data, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 615, in __to_tensor
    raise ValueError(
ValueError: `self.log(val/loss, tensor([[[[ 0.2195,  0.2982,  0.3717,  ...,  0.4118,  0.4388,  0.3824],
          [ 0.2094,  0.1984,  0.2398,  ...,  0.2830,  0.3298,  0.3857],
          [ 0.1702,  0.0632,  0.1131,  ...,  0.1966,  0.2563,  0.3384],
          ...,
          [ 0.2804,  0.2691,  0.2312,  ...,  0.0853,  0.0919,  0.1193],
          [ 0.3140,  0.3025,  0.2404,  ...,  0.0854,  0.0893,  0.1079],
          [ 0.3105,  0.3047,  0.2825,  ...,  0.1090,  0.1034,  0.1005]]],


        [[[-0.0225, -0.0039,  0.0139,  ...,  0.1316,  0.1103,  0.0732],
          [-0.0258,  0.0018,  0.0187,  ...,  0.0987,  0.0786,  0.0795],
          [ 0.0135,  0.0328,  0.0533,  ...,  0.0531,  0.0423,  0.0515],
          ...,
          [-0.0598, -0.0627, -0.0678,  ..., -0.1054, -0.1151, -0.0946],
          [-0.0632, -0.0692, -0.0707,  ..., -0.1054, -0.1071, -0.0789],
          [-0.0531, -0.0677, -0.0609,  ..., -0.0934, -0.0881, -0.0706]]],


        [[[-0.1486, -0.2259, -0.2914,  ..., -0.0760, -0.0549, -0.0582],
          [-0.1897, -0.2416, -0.2513,  ..., -0.1402, -0.1069, -0.0725],
          [-0.2150, -0.2463, -0.1819,  ..., -0.1456, -0.1169, -0.0823],
          ...,
          [ 0.3815,  0.3938,  0.3973,  ..., -0.1041, -0.0767, -0.0546],
          [ 0.4756,  0.5176,  0.4933,  ..., -0.1026, -0.0819, -0.0527],
          [ 0.4903,  0.5259,  0.5244,  ..., -0.0872, -0.0708, -0.0513]]],


        ...,


        [[[-0.0374, -0.0302, -0.0139,  ..., -0.0596, -0.0603, -0.0553],
          [-0.0533, -0.0618, -0.0557,  ..., -0.1040, -0.0980, -0.0699],
          [-0.0380, -0.0459, -0.0433,  ..., -0.0967, -0.0939, -0.0666],
          ...,
          [-0.0900, -0.0934, -0.1036,  ..., -0.1250, -0.1108, -0.0884],
          [-0.0875, -0.0914, -0.0959,  ..., -0.1119, -0.1021, -0.0762],
          [-0.0739, -0.0882, -0.0849,  ..., -0.1023, -0.0931, -0.0717]]],


        [[[-0.0682, -0.0533, -0.0198,  ..., -0.0062, -0.0095, -0.0157],
          [-0.0840, -0.0776, -0.0551,  ..., -0.0503, -0.0469, -0.0234],
          [-0.0661, -0.0645, -0.0497,  ..., -0.0500, -0.0430, -0.0178],
          ...,
          [-0.0623, -0.0632, -0.0697,  ..., -0.1504, -0.1547, -0.1306],
          [-0.0544, -0.0598, -0.0621,  ..., -0.1471, -0.1450, -0.1200],
          [-0.0396, -0.0561, -0.0498,  ..., -0.1443, -0.1314, -0.1124]]],


        [[[ 0.0671,  0.0663,  0.0653,  ..., -0.0149, -0.0078, -0.0134],
          [ 0.0562,  0.0505,  0.0575,  ..., -0.0615, -0.0507, -0.0283],
          [ 0.0485,  0.0383,  0.0639,  ..., -0.0503, -0.0405, -0.0216],
          ...,
          [-0.0451, -0.0402,  0.0109,  ..., -0.1304, -0.1250, -0.1108],
          [-0.1051, -0.1075, -0.0682,  ..., -0.1240, -0.1187, -0.0985],
          [-0.1062, -0.1166, -0.1083,  ..., -0.1148, -0.1074, -0.0912]]]],
       device='cuda:0'))` was called, but the tensor must have a single element. You can try doing `self.log(val/loss, tensor([[[[ 0.2195,  0.2982,  0.3717,  ...,  0.4118,  0.4388,  0.3824],
          [ 0.2094,  0.1984,  0.2398,  ...,  0.2830,  0.3298,  0.3857],
          [ 0.1702,  0.0632,  0.1131,  ...,  0.1966,  0.2563,  0.3384],
          ...,
          [ 0.2804,  0.2691,  0.2312,  ...,  0.0853,  0.0919,  0.1193],
          [ 0.3140,  0.3025,  0.2404,  ...,  0.0854,  0.0893,  0.1079],
          [ 0.3105,  0.3047,  0.2825,  ...,  0.1090,  0.1034,  0.1005]]],


        [[[-0.0225, -0.0039,  0.0139,  ...,  0.1316,  0.1103,  0.0732],
          [-0.0258,  0.0018,  0.0187,  ...,  0.0987,  0.0786,  0.0795],
          [ 0.0135,  0.0328,  0.0533,  ...,  0.0531,  0.0423,  0.0515],
          ...,
          [-0.0598, -0.0627, -0.0678,  ..., -0.1054, -0.1151, -0.0946],
          [-0.0632, -0.0692, -0.0707,  ..., -0.1054, -0.1071, -0.0789],
          [-0.0531, -0.0677, -0.0609,  ..., -0.0934, -0.0881, -0.0706]]],


        [[[-0.1486, -0.2259, -0.2914,  ..., -0.0760, -0.0549, -0.0582],
          [-0.1897, -0.2416, -0.2513,  ..., -0.1402, -0.1069, -0.0725],
          [-0.2150, -0.2463, -0.1819,  ..., -0.1456, -0.1169, -0.0823],
          ...,
          [ 0.3815,  0.3938,  0.3973,  ..., -0.1041, -0.0767, -0.0546],
          [ 0.4756,  0.5176,  0.4933,  ..., -0.1026, -0.0819, -0.0527],
          [ 0.4903,  0.5259,  0.5244,  ..., -0.0872, -0.0708, -0.0513]]],


        ...,


        [[[-0.0374, -0.0302, -0.0139,  ..., -0.0596, -0.0603, -0.0553],
          [-0.0533, -0.0618, -0.0557,  ..., -0.1040, -0.0980, -0.0699],
          [-0.0380, -0.0459, -0.0433,  ..., -0.0967, -0.0939, -0.0666],
          ...,
          [-0.0900, -0.0934, -0.1036,  ..., -0.1250, -0.1108, -0.0884],
          [-0.0875, -0.0914, -0.0959,  ..., -0.1119, -0.1021, -0.0762],
          [-0.0739, -0.0882, -0.0849,  ..., -0.1023, -0.0931, -0.0717]]],


        [[[-0.0682, -0.0533, -0.0198,  ..., -0.0062, -0.0095, -0.0157],
          [-0.0840, -0.0776, -0.0551,  ..., -0.0503, -0.0469, -0.0234],
          [-0.0661, -0.0645, -0.0497,  ..., -0.0500, -0.0430, -0.0178],
          ...,
          [-0.0623, -0.0632, -0.0697,  ..., -0.1504, -0.1547, -0.1306],
          [-0.0544, -0.0598, -0.0621,  ..., -0.1471, -0.1450, -0.1200],
          [-0.0396, -0.0561, -0.0498,  ..., -0.1443, -0.1314, -0.1124]]],


        [[[ 0.0671,  0.0663,  0.0653,  ..., -0.0149, -0.0078, -0.0134],
          [ 0.0562,  0.0505,  0.0575,  ..., -0.0615, -0.0507, -0.0283],
          [ 0.0485,  0.0383,  0.0639,  ..., -0.0503, -0.0405, -0.0216],
          ...,
          [-0.0451, -0.0402,  0.0109,  ..., -0.1304, -0.1250, -0.1108],
          [-0.1051, -0.1075, -0.0682,  ..., -0.1240, -0.1187, -0.0985],
          [-0.1062, -0.1166, -0.1083,  ..., -0.1148, -0.1074, -0.0912]]]],
       device='cuda:0').mean())`
[2025-04-01 17:28:13,872][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-01_17-26-38
[2025-04-01 17:38:58,424][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-01 17:38:58,434][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-01 17:38:58,554][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-01 17:38:58,771][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-01 17:38:58,771][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-01 17:38:59,549][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-01 17:39:03,046][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-01 17:39:06,263][__main__][INFO] - Instantiating callbacks...
[2025-04-01 17:39:06,264][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-01 17:39:06,269][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-01 17:39:06,270][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-01 17:39:06,271][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-01 17:39:06,271][__main__][INFO] - Instantiating loggers...
[2025-04-01 17:39:06,272][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-01 17:39:06,274][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-01 17:39:07,653][__main__][INFO] - Logging hyperparameters!
[2025-04-01 17:39:13,384][__main__][INFO] - Starting training!
[2025-04-01 17:39:43,179][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-01 17:39:43,180][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-01 17:40:29,839][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 65, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1014, in _run_stage
    self._run_sanity_check()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1043, in _run_sanity_check
    val_loop.run()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 115, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 375, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_kwargs.values())
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 336, in validation_step
    return self.model(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/overrides/base.py", line 102, in forward
    return self._forward_module.validation_step(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 321, in validation_step
    loss = self.shared_step(batch)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 299, in shared_step
    residual, _ = self.autoencoder.preprocess_batch([x, y, z])
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ae_module.py", line 129, in preprocess_batch
    residual = high_res - self.unet(low_res)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ae_module.py", line 145, in unet
    return self.unet_regr(x)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/unet_module.py", line 66, in forward
    return self.net(x)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/components/unet.py", line 81, in forward
    d3 = self.d3(d2, s2)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/components/unet.py", line 44, in forward
    x = self.conv(x)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/components/unet.py", line 19, in forward
    x = self.conv(inputs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 23.67 GiB total capacity; 4.69 GiB already allocated; 238.00 MiB free; 5.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2025-04-01 17:40:29,853][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-01_17-38-58
[2025-04-01 17:42:14,400][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-01 17:42:14,407][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-01 17:42:14,524][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-01 17:42:14,772][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-01 17:42:14,773][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-01 17:42:15,648][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-01 17:42:19,386][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-01 17:42:22,598][__main__][INFO] - Instantiating callbacks...
[2025-04-01 17:42:22,598][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-01 17:42:22,607][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-01 17:42:22,608][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-01 17:42:22,609][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-01 17:42:22,610][__main__][INFO] - Instantiating loggers...
[2025-04-01 17:42:22,610][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-01 17:42:22,613][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-01 17:42:23,952][__main__][INFO] - Logging hyperparameters!
[2025-04-01 17:42:28,218][__main__][INFO] - Starting training!
[2025-04-01 17:42:58,078][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-01 17:42:58,078][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-01 17:50:19,503][__main__][INFO] - Starting testing!
[2025-04-01 17:50:19,520][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-04-01 17:51:30,132][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-01 17:51:30,139][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-01 17:51:30,234][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-01 17:51:30,671][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-01 17:51:30,672][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-01 17:51:31,738][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-01 17:51:37,036][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-01 17:51:54,630][__main__][INFO] - Instantiating callbacks...
[2025-04-01 17:51:54,631][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-01 17:51:54,638][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-01 17:51:54,639][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-01 17:51:54,640][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-01 17:51:54,642][__main__][INFO] - Instantiating loggers...
[2025-04-01 17:51:54,643][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-01 17:51:54,644][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-01 17:51:56,108][__main__][INFO] - Logging hyperparameters!
[2025-04-01 17:52:05,959][__main__][INFO] - Starting training!
[2025-04-01 17:52:39,611][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-01 17:52:39,612][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-01 20:34:54,388][__main__][INFO] - Starting testing!
[2025-04-01 20:38:22,637][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-01_17-51-30/checkpoints/epoch_003.ckpt
[2025-04-01 20:38:22,855][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-01_17-51-30
[2025-04-01 20:38:22,855][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.2414286583662033>
[2025-04-01 21:17:34,989][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-01 21:17:34,996][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-01 21:17:35,118][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-01 21:17:35,700][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-01 21:17:35,700][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-01 21:17:36,704][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-01 21:17:42,258][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-01 21:17:51,265][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-01_21-17-34
[2025-04-04 11:14:54,619][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-04 11:14:54,627][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-04 11:14:54,722][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-04 11:14:55,424][numexpr.utils][INFO] - Note: NumExpr detected 64 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-04 11:14:55,425][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-04 11:14:56,615][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-04 11:15:01,867][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-04 11:15:18,302][__main__][INFO] - Instantiating callbacks...
[2025-04-04 11:15:18,303][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-04 11:15:18,310][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-04 11:15:18,311][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-04 11:15:18,311][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-04 11:15:18,312][__main__][INFO] - Instantiating loggers...
[2025-04-04 11:15:18,313][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-04 11:15:18,314][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-04 11:15:19,533][__main__][INFO] - Logging hyperparameters!
[2025-04-04 11:15:30,064][__main__][INFO] - Starting training!
[2025-04-04 11:16:02,625][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-04 11:16:02,625][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-04 17:37:49,952][__main__][INFO] - Starting testing!
[2025-04-04 17:41:11,085][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-04_11-14-54/checkpoints/epoch_019.ckpt
[2025-04-04 17:41:11,231][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-04_11-14-54
[2025-04-04 17:41:11,231][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.2386205494403839>
[2025-04-04 23:01:22,850][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-04 23:01:22,856][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-04 23:01:22,938][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-04 23:01:23,117][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-04 23:01:23,117][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-04 23:01:23,749][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-04 23:01:28,409][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-04 23:01:31,607][__main__][INFO] - Instantiating callbacks...
[2025-04-04 23:01:31,608][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-04 23:01:31,613][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-04 23:01:31,614][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-04 23:01:31,614][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-04 23:01:31,615][__main__][INFO] - Instantiating loggers...
[2025-04-04 23:01:31,615][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-04 23:01:31,617][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-04 23:01:33,081][__main__][INFO] - Logging hyperparameters!
[2025-04-04 23:01:40,065][__main__][INFO] - Starting training!
[2025-04-04 23:02:09,902][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-04 23:02:09,904][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-05 06:27:16,461][__main__][INFO] - Starting testing!
[2025-04-05 06:31:02,198][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-04_23-01-22/checkpoints/epoch_019.ckpt
[2025-04-05 06:31:02,459][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-04_23-01-22
[2025-04-05 06:31:02,459][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.29873377084732056>
[2025-04-05 11:36:38,786][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-05 11:36:38,795][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-05 11:36:38,886][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-05 11:36:39,124][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-05 11:36:39,125][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-05 11:36:39,978][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-05 11:36:44,916][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-05 11:36:56,857][__main__][INFO] - Instantiating callbacks...
[2025-04-05 11:36:56,858][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-05 11:36:56,861][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-05 11:36:56,862][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-05 11:36:56,863][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-05 11:36:56,864][__main__][INFO] - Instantiating loggers...
[2025-04-05 11:36:56,864][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-05 11:36:56,866][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-05 11:36:58,118][__main__][INFO] - Logging hyperparameters!
[2025-04-05 11:37:02,460][__main__][INFO] - Starting training!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [2025-04-05 11:37:35,210][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-05 11:37:35,211][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-05 11:38:02,184][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-05 11:38:02,185][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-05 11:38:10,517][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-05 11:38:10,524][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-05 11:38:10,618][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-05 11:38:10,979][numexpr.utils][INFO] - Note: NumExpr detected 64 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-05 11:38:10,979][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-05 11:38:11,745][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-05 11:38:16,781][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-05 11:38:27,655][__main__][INFO] - Instantiating callbacks...
[2025-04-05 11:38:27,656][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-05 11:38:27,661][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-05 11:38:27,662][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-05 11:38:27,662][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-05 11:38:27,665][__main__][INFO] - Instantiating loggers...
[2025-04-05 11:38:27,665][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-05 11:38:27,667][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-05 11:38:28,901][__main__][INFO] - Logging hyperparameters!
[2025-04-05 11:38:39,380][__main__][INFO] - Starting training!
[2025-04-05 11:39:10,403][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-05 11:39:10,403][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-05 18:05:41,873][__main__][INFO] - Starting testing!
[2025-04-05 18:09:06,645][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-05_11-38-10/checkpoints/epoch_019.ckpt
[2025-04-05 18:09:06,811][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-05_11-38-10
[2025-04-05 18:09:06,812][src.utils.utils][INFO] - Retrieved metric value! <val/loss=2.203439474105835>
[2025-04-05 18:59:02,635][__main__][INFO] - Starting testing!
[2025-04-05 19:02:58,015][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-05_11-37-06/checkpoints/epoch_019.ckpt
[2025-04-05 19:02:58,216][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-05_11-37-06
[2025-04-05 19:02:58,217][src.utils.utils][INFO] - Retrieved metric value! <val/loss=1.7564607858657837>
[2025-04-05 19:19:15,452][__main__][INFO] - Starting testing!
[2025-04-05 19:23:14,125][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-05_11-36-38/checkpoints/epoch_019.ckpt
[2025-04-05 19:23:14,336][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-05_11-36-38
[2025-04-05 19:23:14,336][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.5232238173484802>
[2025-04-06 13:25:46,971][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-06 13:25:46,979][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-06 13:25:47,067][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-06 13:25:47,280][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-06 13:25:47,281][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-06 13:25:47,953][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-06 13:25:47,883][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-06 13:25:55,183][__main__][INFO] - Instantiating callbacks...
[2025-04-06 13:25:55,184][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-06 13:25:55,187][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-06 13:25:55,188][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-06 13:25:55,188][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-06 13:25:55,189][__main__][INFO] - Instantiating loggers...
[2025-04-06 13:25:55,189][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-06 13:25:55,190][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
                                                                     [2025-04-06 13:25:56,382][__main__][INFO] - Logging hyperparameters!
[2025-04-06 13:26:02,614][__main__][INFO] - Starting training!
[2025-04-06 13:26:36,027][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-06 13:26:36,027][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-06 20:22:28,255][__main__][INFO] - Starting testing!
[2025-04-06 20:26:16,234][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-06_13-25-46/checkpoints/epoch_019.ckpt
[2025-04-06 20:26:16,448][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-06_13-25-46
[2025-04-06 20:26:16,448][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.6975281238555908>
[2025-04-06 20:26:37,743][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-06 20:26:37,749][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-06 20:26:37,826][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-06 20:26:37,999][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-06 20:26:37,999][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-06 20:26:38,426][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-06 20:26:42,909][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-06 20:27:11,339][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-06 20:27:11,344][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-06 20:27:11,416][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-06 20:27:11,507][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-06 20:27:11,507][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-06 20:27:11,773][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-06 20:27:14,933][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-06 20:27:27,481][__main__][INFO] - Instantiating callbacks...
[2025-04-06 20:27:27,482][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-06 20:27:27,486][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-06 20:27:27,487][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-06 20:27:27,487][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-06 20:27:27,488][__main__][INFO] - Instantiating loggers...
[2025-04-06 20:27:27,488][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-06 20:27:27,489][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-06 20:27:28,558][__main__][INFO] - Logging hyperparameters!
[2025-04-06 20:27:32,432][__main__][INFO] - Starting training!
[2025-04-06 20:27:58,555][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-06 20:27:58,555][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-06 20:28:28,534][__main__][INFO] - Starting testing!
[2025-04-06 20:32:11,715][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-06_13-25-41/checkpoints/epoch_019.ckpt
[2025-04-06 20:32:12,088][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-06_13-25-41
[2025-04-06 20:32:12,089][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.6988036632537842>
[2025-04-06 21:17:29,695][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-06 21:17:29,700][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-06 21:17:29,777][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-06 21:17:29,902][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-06 21:17:29,903][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-06 21:17:30,449][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-06 21:17:33,377][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-06 21:17:36,320][__main__][INFO] - Instantiating callbacks...
[2025-04-06 21:17:36,320][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-06 21:17:36,324][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-06 21:17:36,325][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-06 21:17:36,326][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-06 21:17:36,326][__main__][INFO] - Instantiating loggers...
[2025-04-06 21:17:36,326][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-06 21:17:36,328][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-06 21:17:37,362][__main__][INFO] - Logging hyperparameters!
[2025-04-06 21:17:40,776][__main__][INFO] - Starting training!
[2025-04-06 21:18:05,897][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-06 21:18:05,898][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-06 21:18:33,160][__main__][INFO] - Starting testing!
[2025-04-06 21:18:33,161][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-04-06 21:19:03,138][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-06 21:19:03,143][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-06 21:19:03,224][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-06 21:19:03,366][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-06 21:19:03,366][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-06 21:19:03,737][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-06 21:19:06,851][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-06 21:19:09,133][__main__][INFO] - Instantiating callbacks...
[2025-04-06 21:19:09,134][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-06 21:19:09,137][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-06 21:19:09,138][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-06 21:19:09,139][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-06 21:19:09,139][__main__][INFO] - Instantiating loggers...
[2025-04-06 21:19:09,139][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-06 21:19:09,141][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-06 21:19:09,434][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/users/par55/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 92, in _call_target
    return _target_(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/utilities/argparse.py", line 69, in insert_env_defaults
    return fn(self, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 398, in __init__
    self._accelerator_connector = _AcceleratorConnector(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py", line 157, in __init__
    self._set_parallel_devices_and_init_accelerator()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py", line 389, in _set_parallel_devices_and_init_accelerator
    self._devices_flag = accelerator_cls.parse_devices(self._devices_flag)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/accelerators/cuda.py", line 81, in parse_devices
    return _parse_gpu_ids(devices, include_cuda=True)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/fabric/utilities/device_parser.py", line 102, in _parse_gpu_ids
    return _sanitize_gpu_ids(gpus, include_cuda=include_cuda, include_mps=include_mps)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/fabric/utilities/device_parser.py", line 134, in _sanitize_gpu_ids
    raise MisconfigurationException(
lightning.fabric.utilities.exceptions.MisconfigurationException: You requested gpu: [0, 1, 2, 3]
 But your machine only has: [0]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 44, in train
    trainer: Trainer = hydra.utils.instantiate(cfg.trainer, callbacks=callbacks, logger=logger)
  File "/home/users/par55/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
  File "/home/users/par55/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 347, in instantiate_node
    return _call_target(_target_, partial, args, kwargs, full_key)
  File "/home/users/par55/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 97, in _call_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error in call to target 'lightning.pytorch.trainer.trainer.Trainer':
MisconfigurationException('You requested gpu: [0, 1, 2, 3]\n But your machine only has: [0]')
full_key: trainer
[2025-04-06 21:19:09,440][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-06_21-19-03
[2025-04-06 21:19:36,737][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-06 21:19:36,745][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-06 21:19:36,821][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-06 21:19:36,929][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-06 21:19:36,929][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-06 21:19:37,291][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-06 21:19:40,412][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-06 21:19:42,686][__main__][INFO] - Instantiating callbacks...
[2025-04-06 21:19:42,687][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-06 21:19:42,691][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-06 21:19:42,692][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-06 21:19:42,693][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-06 21:19:42,694][__main__][INFO] - Instantiating loggers...
[2025-04-06 21:19:42,694][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-06 21:19:42,696][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-06 21:19:42,981][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/users/par55/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 92, in _call_target
    return _target_(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/utilities/argparse.py", line 69, in insert_env_defaults
    return fn(self, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 398, in __init__
    self._accelerator_connector = _AcceleratorConnector(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py", line 157, in __init__
    self._set_parallel_devices_and_init_accelerator()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py", line 389, in _set_parallel_devices_and_init_accelerator
    self._devices_flag = accelerator_cls.parse_devices(self._devices_flag)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/accelerators/cuda.py", line 81, in parse_devices
    return _parse_gpu_ids(devices, include_cuda=True)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/fabric/utilities/device_parser.py", line 102, in _parse_gpu_ids
    return _sanitize_gpu_ids(gpus, include_cuda=include_cuda, include_mps=include_mps)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/fabric/utilities/device_parser.py", line 134, in _sanitize_gpu_ids
    raise MisconfigurationException(
lightning.fabric.utilities.exceptions.MisconfigurationException: You requested gpu: [0, 1, 2, 3]
 But your machine only has: [0]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 44, in train
    trainer: Trainer = hydra.utils.instantiate(cfg.trainer, callbacks=callbacks, logger=logger)
  File "/home/users/par55/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
  File "/home/users/par55/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 347, in instantiate_node
    return _call_target(_target_, partial, args, kwargs, full_key)
  File "/home/users/par55/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 97, in _call_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error in call to target 'lightning.pytorch.trainer.trainer.Trainer':
MisconfigurationException('You requested gpu: [0, 1, 2, 3]\n But your machine only has: [0]')
full_key: trainer
[2025-04-06 21:19:42,984][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-06_21-19-36
[2025-04-06 21:20:30,111][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-06 21:20:30,117][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-06 21:20:30,191][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-06 21:20:30,300][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-06 21:20:30,300][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-06 21:20:30,646][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-06 21:20:33,672][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-06 21:20:36,041][__main__][INFO] - Instantiating callbacks...
[2025-04-06 21:20:36,042][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-06 21:20:36,046][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-06 21:20:36,048][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-06 21:20:36,048][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-06 21:20:36,050][__main__][INFO] - Instantiating loggers...
[2025-04-06 21:20:36,050][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-06 21:20:36,052][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-06 21:20:37,318][__main__][INFO] - Logging hyperparameters!
[2025-04-06 21:20:43,649][__main__][INFO] - Starting training!
[2025-04-06 21:20:44,041][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-06 21:20:44,041][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2025-04-06 21:20:57,143][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 65, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1014, in _run_stage
    self._run_sanity_check()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1043, in _run_sanity_check
    val_loop.run()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 115, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 375, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_kwargs.values())
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 336, in validation_step
    return self.model(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/overrides/base.py", line 102, in forward
    return self._forward_module.validation_step(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 321, in validation_step
    loss = self.shared_step(batch)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 299, in shared_step
    residual, _ = self.autoencoder.preprocess_batch([x, y, z])
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ae_module.py", line 129, in preprocess_batch
    residual = high_res - self.unet(low_res)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ae_module.py", line 145, in unet
    return self.unet_regr(x)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/unet_module.py", line 66, in forward
    return self.net(x)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/components/unet.py", line 81, in forward
    d3 = self.d3(d2, s2)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/components/unet.py", line 43, in forward
    x = torch.cat([x, skip], axis=1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 23.67 GiB total capacity; 3.28 GiB already allocated; 231.69 MiB free; 3.80 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2025-04-06 21:20:57,160][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-06_21-20-30
[2025-04-06 21:21:26,155][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-06 21:21:26,161][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-06 21:21:26,239][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-06 21:21:26,350][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-06 21:21:26,350][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-06 21:21:26,646][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-06 21:21:33,942][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-06 21:21:36,406][__main__][INFO] - Instantiating callbacks...
[2025-04-06 21:21:36,409][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-06 21:21:36,413][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-06 21:21:36,415][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-06 21:21:36,416][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-06 21:21:36,416][__main__][INFO] - Instantiating loggers...
[2025-04-06 21:21:36,417][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-06 21:21:36,419][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-06 21:21:37,805][__main__][INFO] - Logging hyperparameters!
[2025-04-06 21:21:41,170][__main__][INFO] - Starting training!
[2025-04-06 21:21:41,551][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-06 21:21:41,552][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2025-04-06 21:23:17,186][__main__][INFO] - Starting testing!
[2025-04-06 21:23:17,198][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-04-06 21:23:23,604][__main__][INFO] - Best ckpt path: None
[2025-04-06 21:23:23,757][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-06_21-21-26
[2025-04-06 21:23:42,137][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-06 21:23:42,143][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-06 21:23:42,223][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-06 21:23:42,343][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-06 21:23:42,343][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-06 21:23:42,790][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-06 21:23:46,123][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-06 21:23:48,602][__main__][INFO] - Instantiating callbacks...
[2025-04-06 21:23:48,603][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-06 21:23:48,607][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-06 21:23:48,608][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-06 21:23:48,608][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-06 21:23:48,609][__main__][INFO] - Instantiating loggers...
[2025-04-06 21:23:48,609][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-06 21:23:48,611][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-06 21:23:50,058][__main__][INFO] - Logging hyperparameters!
[2025-04-06 21:23:53,591][__main__][INFO] - Starting training!
[2025-04-06 21:23:53,986][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-06 21:23:53,986][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2025-04-06 21:25:37,987][__main__][INFO] - Starting testing!
[2025-04-06 21:25:37,994][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-04-06 21:25:44,458][__main__][INFO] - Best ckpt path: None
[2025-04-06 21:25:44,814][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-06_21-23-42
[2025-04-06 21:26:04,720][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-06 21:26:04,726][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-06 21:26:04,805][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-06 21:26:04,938][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-06 21:26:04,939][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-06 21:26:05,360][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-06 21:26:11,038][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-06 21:27:19,688][__main__][INFO] - Instantiating callbacks...
[2025-04-06 21:27:19,690][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-06 21:27:19,694][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-06 21:27:19,695][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-06 21:27:19,696][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-06 21:27:19,698][__main__][INFO] - Instantiating loggers...
[2025-04-06 21:27:19,698][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-06 21:27:19,700][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-06 21:27:21,375][__main__][INFO] - Logging hyperparameters!
[2025-04-06 21:27:25,013][__main__][INFO] - Starting training!
[2025-04-06 21:27:25,432][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-06 21:27:25,432][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2025-04-06 21:56:12,024][__main__][INFO] - Starting testing!
[2025-04-06 23:29:50,884][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-06 23:29:50,891][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-06 23:29:50,981][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-06 23:29:51,460][numexpr.utils][INFO] - Note: NumExpr detected 64 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-06 23:29:51,460][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-06 23:29:52,394][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-06 23:29:58,093][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-06 23:30:14,062][__main__][INFO] - Instantiating callbacks...
[2025-04-06 23:30:14,064][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-06 23:30:14,068][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-06 23:30:14,069][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-06 23:30:14,069][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-06 23:30:14,071][__main__][INFO] - Instantiating loggers...
[2025-04-06 23:30:14,071][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-06 23:30:14,072][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-06 23:30:15,205][__main__][INFO] - Logging hyperparameters!
[2025-04-06 23:30:23,863][__main__][INFO] - Starting training!
[2025-04-06 23:30:56,281][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-06 23:30:56,282][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-07 00:23:12,745][__main__][INFO] - Starting testing!
[2025-04-07 00:30:52,538][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-06_21-26-04/checkpoints/epoch_002.ckpt
[2025-04-07 00:30:52,711][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-06_21-26-04
[2025-04-07 00:30:52,712][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.24029934406280518>
[2025-04-07 00:53:28,955][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-07 00:53:28,962][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-07 00:53:29,062][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-07 00:53:29,551][numexpr.utils][INFO] - Note: NumExpr detected 64 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-07 00:53:29,552][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-07 00:53:30,379][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-07 00:53:35,726][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-07 00:53:49,963][__main__][INFO] - Instantiating callbacks...
[2025-04-07 00:53:49,964][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-07 00:53:49,969][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-07 00:53:49,970][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-07 00:53:49,971][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-07 00:53:49,973][__main__][INFO] - Instantiating loggers...
[2025-04-07 00:53:49,973][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-07 00:53:49,974][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-07 00:53:51,199][__main__][INFO] - Logging hyperparameters!
.
[2025-04-07 00:53:50,669][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-07 00:53:50,673][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-07 00:53:50,674][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-07 00:53:50,674][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-07 00:53:50,677][__main__][INFO] - Instantiating loggers...
[2025-04-07 00:53:50,677][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-07 00:53:50,679][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-07 00:53:51,872][__main__][INFO] - Logging hyperparameters!
[2025-04-07 00:54:00,784][__main__][INFO] - Starting training!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [2025-04-07 00:54:34,664][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-07 00:54:34,665][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-07 00:54:59,385][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-07 00:54:59,386][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-07 00:55:54,621][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-07 00:55:54,629][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-07 00:55:54,716][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-07 00:55:55,068][numexpr.utils][INFO] - Note: NumExpr detected 64 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-07 00:55:55,068][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-07 00:55:55,727][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-07 00:56:01,285][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-07 00:56:16,755][__main__][INFO] - Instantiating callbacks...
[2025-04-07 00:56:16,755][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-07 00:56:16,760][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-07 00:56:16,761][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-07 00:56:16,761][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-07 00:56:16,763][__main__][INFO] - Instantiating loggers...
[2025-04-07 00:56:16,763][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-07 00:56:16,764][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-07 00:56:17,988][__main__][INFO] - Logging hyperparameters!
[2025-04-07 00:56:23,356][__main__][INFO] - Starting training!
[2025-04-07 00:56:54,038][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-07 00:56:54,038][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [2025-04-07 05:08:55,067][__main__][INFO] - Starting testing!
[2025-04-07 05:12:05,295][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-07_00-55-54/checkpoints/epoch_011.ckpt
[2025-04-07 05:12:05,462][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-07_00-55-54
[2025-04-07 05:12:05,463][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.24639806151390076>
[2025-04-07 05:51:26,385][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 65, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1016, in _run_stage
    self.fit_loop.run()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 201, in run
    self.advance()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 354, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 133, in run
    self.advance(data_fetcher)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 218, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 185, in run
    self._optimizer_step(kwargs.get("batch_idx", 0), closure)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 260, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 144, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 362, in optimizer_step
    super().optimizer_step(epoch, batch_idx, optimizer, optimizer_closure, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/core/module.py", line 1256, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/core/optimizer.py", line 155, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 256, in optimizer_step
    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 225, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py", line 114, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 33, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 148, in step
    loss = closure()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py", line 101, in _wrap_closure
    closure_result = closure()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 140, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 126, in closure
    step_output = self._step_fn()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 307, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 328, in training_step
    return self.model(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/overrides/base.py", line 90, in forward
    output = self._forward_module.training_step(*inputs, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 315, in training_step
    loss = self.shared_step(batch)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 312, in shared_step
    return self(latent_target, context=context_dict)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 291, in forward
    return self.p_losses(x, t, *args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 284, in p_losses
    pde_loss_val = self.temperature_pde_loss(T_f, T_c)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 129, in temperature_pde_loss
    grad_T_c = torch.sqrt(dT_c_dx**2 + dT_c_dy**2 + 1e-8)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 224.00 MiB (GPU 0; 22.18 GiB total capacity; 19.82 GiB already allocated; 139.75 MiB free; 21.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2025-04-07 05:51:26,414][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-06_23-29-50
[2025-04-07 10:55:30,155][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-07 10:55:30,163][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-07 10:55:30,242][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-07 10:55:30,386][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-07 10:55:30,386][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-07 10:55:30,853][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-07 10:55:34,608][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-07 10:55:37,395][__main__][INFO] - Instantiating callbacks...
[2025-04-07 10:55:37,395][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-07 10:55:37,398][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-07 10:55:37,399][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-07 10:55:37,399][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-07 10:55:37,400][__main__][INFO] - Instantiating loggers...
[2025-04-07 10:55:37,400][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-07 10:55:37,401][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-07 10:55:38,580][__main__][INFO] - Logging hyperparameters!
[2025-04-07 10:55:42,697][__main__][INFO] - Starting training!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [2025-04-07 10:56:13,469][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-07 10:56:13,470][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-07 10:56:27,087][__main__][INFO] - Instantiating callbacks...
[2025-04-07 10:56:27,088][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-07 10:56:27,094][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-07 10:56:27,095][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-07 10:56:27,096][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-07 10:56:27,098][__main__][INFO] - Instantiating loggers...
[2025-04-07 10:56:27,098][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-07 10:56:27,100][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-07 10:56:28,366][__main__][INFO] - Logging hyperparameters!
[2025-04-07 10:56:37,253][__main__][INFO] - Starting training!
[2025-04-07 10:57:09,025][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-07 10:57:09,026][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-07 13:09:34,514][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-07 13:09:34,521][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-07 13:09:34,600][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-07 13:09:34,835][numexpr.utils][INFO] - Note: NumExpr detected 64 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-07 13:09:34,835][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-07 13:09:35,558][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-07 13:09:39,226][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-07 13:09:42,198][__main__][INFO] - Instantiating callbacks...
[2025-04-07 13:09:42,199][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-07 13:09:42,202][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-07 13:09:42,203][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-07 13:09:42,204][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-07 13:09:42,204][__main__][INFO] - Instantiating loggers...
[2025-04-07 13:09:42,204][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-07 13:09:42,206][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-07 13:09:43,445][__main__][INFO] - Logging hyperparameters!
[2025-04-07 13:09:48,367][__main__][INFO] - Starting training!
[2025-04-07 13:10:20,987][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-07 13:10:20,987][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [2025-04-07 16:28:39,033][__main__][INFO] - Starting testing!
[2025-04-07 16:31:44,004][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-07_13-09-34/checkpoints/epoch_007.ckpt
[2025-04-07 16:31:44,186][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-07_13-09-34
[2025-04-07 16:31:44,186][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.4632647633552551>
[2025-04-07 17:00:02,982][__main__][INFO] - Starting testing!
[2025-04-07 17:03:05,255][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-07_13-11-04/checkpoints/epoch_009.ckpt
[2025-04-07 17:03:05,457][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-07_13-11-04
[2025-04-07 17:03:05,457][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.46977055072784424>
[2025-04-07 20:06:24,764][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-07 20:06:24,769][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-07 20:06:24,858][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-07 20:06:25,009][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-07 20:06:25,009][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-07 20:06:25,372][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-07 20:06:29,218][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-07 20:06:31,574][__main__][INFO] - Instantiating callbacks...
[2025-04-07 20:06:31,574][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-07 20:06:31,578][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-07 20:06:31,579][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-07 20:06:31,580][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-07 20:06:31,580][__main__][INFO] - Instantiating loggers...
[2025-04-07 20:06:31,581][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-07 20:06:31,582][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-07 20:06:31,857][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/users/par55/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 92, in _call_target
    return _target_(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/utilities/argparse.py", line 69, in insert_env_defaults
    return fn(self, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 398, in __init__
    self._accelerator_connector = _AcceleratorConnector(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py", line 157, in __init__
    self._set_parallel_devices_and_init_accelerator()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py", line 389, in _set_parallel_devices_and_init_accelerator
    self._devices_flag = accelerator_cls.parse_devices(self._devices_flag)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/accelerators/cuda.py", line 81, in parse_devices
    return _parse_gpu_ids(devices, include_cuda=True)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/fabric/utilities/device_parser.py", line 102, in _parse_gpu_ids
    return _sanitize_gpu_ids(gpus, include_cuda=include_cuda, include_mps=include_mps)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/fabric/utilities/device_parser.py", line 134, in _sanitize_gpu_ids
    raise MisconfigurationException(
lightning.fabric.utilities.exceptions.MisconfigurationException: You requested gpu: [0, 1, 2, 3]
 But your machine only has: [0]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 44, in train
    trainer: Trainer = hydra.utils.instantiate(cfg.trainer, callbacks=callbacks, logger=logger)
  File "/home/users/par55/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
  File "/home/users/par55/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 347, in instantiate_node
    return _call_target(_target_, partial, args, kwargs, full_key)
  File "/home/users/par55/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 97, in _call_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error in call to target 'lightning.pytorch.trainer.trainer.Trainer':
MisconfigurationException('You requested gpu: [0, 1, 2, 3]\n But your machine only has: [0]')
full_key: trainer
[2025-04-07 20:06:31,863][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-07_20-06-24
[2025-04-07 20:06:42,388][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-07 20:06:42,395][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-07 20:06:42,493][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-07 20:06:42,762][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-07 20:06:46,621][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/users/mb625/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 92, in _call_target
    return _target_(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/unet_module.py", line 47, in __init__
    self.init_from_ckpt(ckpt_path, ignore_keys=ignore_keys)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/unet_module.py", line 50, in init_from_ckpt
    sd = torch.load(path, map_location="cpu")["state_dict"]
  File "/home/users/mb625/.local/lib/python3.10/site-packages/torch/serialization.py", line 1470, in load
    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL functools.partial was not an allowed global by default. Please use `torch.serialization.add_safe_globals([partial])` or the `torch.serialization.safe_globals([partial])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 26, in train
    model: LightningModule = hydra.utils.instantiate(cfg.model)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
  File "/home/users/mb625/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 342, in instantiate_node
    value = instantiate_node(
  File "/home/users/mb625/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 342, in instantiate_node
    value = instantiate_node(
  File "/home/users/mb625/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 347, in instantiate_node
    return _call_target(_target_, partial, args, kwargs, full_key)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 97, in _call_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error in call to target 'src.models.unet_module.UnetLitModule':
UnpicklingError('Weights only load failed. This file can still be loaded, to do so you have two options, \x1b[1mdo those steps only if you trust the source of the checkpoint\x1b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL functools.partial was not an allowed global by default. Please use `torch.serialization.add_safe_globals([partial])` or the `torch.serialization.safe_globals([partial])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.')
full_key: model.autoencoder.unet_regr
[2025-04-07 20:06:46,634][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-07_20-06-42
[2025-04-07 20:08:45,665][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-07 20:08:45,673][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-07 20:08:45,758][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-07 20:08:46,002][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-07 20:08:50,235][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-07 20:09:12,643][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 33, in train
    ckpt = torch.load(ckpt_path, map_location="cpu")
  File "/home/users/mb625/.local/lib/python3.10/site-packages/torch/serialization.py", line 1470, in load
    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL omegaconf.dictconfig.DictConfig was not an allowed global by default. Please use `torch.serialization.add_safe_globals([DictConfig])` or the `torch.serialization.safe_globals([DictConfig])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
[2025-04-07 20:09:12,738][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-07_20-08-45
[2025-04-07 20:09:57,932][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-07 20:09:57,940][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-07 20:09:58,034][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-07 20:09:58,281][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-07 20:10:04,171][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-07 20:10:37,606][__main__][INFO] - Instantiating callbacks...
[2025-04-07 20:10:37,645][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-07 20:10:37,845][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-07 20:10:37,849][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-07 20:10:37,853][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-07 20:10:37,855][__main__][INFO] - Instantiating loggers...
[2025-04-07 20:10:37,856][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-07 20:10:37,907][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-07 20:10:38,190][__main__][INFO] - Logging hyperparameters!
[2025-04-07 20:10:38,933][__main__][INFO] - Starting training!
[2025-04-07 20:26:15,964][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-07 20:26:15,971][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-07 20:26:16,071][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-07 20:26:16,346][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-07 20:26:20,461][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-07 20:26:38,064][__main__][INFO] - Instantiating callbacks...
[2025-04-07 20:26:38,100][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-07 20:26:38,315][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-07 20:26:38,319][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-07 20:26:38,323][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-07 20:26:38,325][__main__][INFO] - Instantiating loggers...
[2025-04-07 20:26:38,326][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-07 20:26:38,378][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-07 20:26:38,629][__main__][INFO] - Logging hyperparameters!
[2025-04-07 20:26:39,159][__main__][INFO] - Starting training!
[2025-04-07 20:35:57,382][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-07 20:35:57,390][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-07 20:35:57,515][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-07 20:35:57,849][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
ers/mb625/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/home/users/mb625/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1054, in _run_stage
    self._run_sanity_check()
  File "/home/users/mb625/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1083, in _run_sanity_check
    val_loop.run()
  File "/home/users/mb625/.local/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 328, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 411, in validation_step
    return self._forward_redirection(self.model, self.lightning_module, "validation_step", *args, **kwargs)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 641, in __call__
    wrapper_output = wrapper_module(*args, **kwargs)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/users/mb625/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 634, in wrapped_forward
    out = method(*_args, **_kwargs)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 321, in validation_step
    loss = self.shared_step(batch)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 299, in shared_step
    residual, _ = self.autoencoder.preprocess_batch([x, y, z])
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ae_module.py", line 128, in preprocess_batch
    low_res = self.nn_lr_and_merge_with_static(low_res, smt)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ae_module.py", line 138, in nn_lr_and_merge_with_static
    low_res = torch.repeat_interleave(low_res, 8, dim=2)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 66, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "/home/users/mb625/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 57, in _call_and_handle_interrupt
    rank_zero_info("\nDetected KeyboardInterrupt, attempting graceful shutdown ...")
  File "/home/users/mb625/.local/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py", line 41, in wrapped_fn
    return fn(*args, **kwargs)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py", line 66, in rank_zero_info
    _info(*args, stacklevel=stacklevel, **kwargs)
  File "/home/users/mb625/.local/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py", line 60, in _info
    log.info(*args, **kwargs)
  File "/home/users/mb625/miniconda3/envs/diff/lib/python3.10/logging/__init__.py", line 1467, in info
    def info(self, msg, *args, **kwargs):
  File "/home/users/mb625/.local/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1340498) is killed by signal: Killed. 
[2025-04-07 20:35:58,100][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-07_20-26-15
[2025-04-07 20:36:03,924][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-07 20:36:38,009][__main__][INFO] - Instantiating callbacks...
[2025-04-07 20:36:38,055][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-07 20:36:38,247][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-07 20:36:38,252][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-07 20:36:38,255][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-07 20:36:38,258][__main__][INFO] - Instantiating loggers...
[2025-04-07 20:36:38,258][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-07 20:36:38,311][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-07 20:36:38,494][__main__][INFO] - Logging hyperparameters!
[2025-04-07 20:36:39,018][__main__][INFO] - Starting training!
[2025-04-07 20:46:46,657][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-07 20:46:46,665][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-07 20:46:46,786][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-07 20:46:47,117][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-07 20:46:53,342][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-07 20:47:27,354][__main__][INFO] - Instantiating callbacks...
[2025-04-07 20:47:27,402][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-07 20:47:27,635][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-07 20:47:27,639][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-07 20:47:27,643][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-07 20:47:27,646][__main__][INFO] - Instantiating loggers...
[2025-04-07 20:47:27,647][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-07 20:47:27,697][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-07 20:47:27,970][__main__][INFO] - Logging hyperparameters!
[2025-04-07 20:47:28,479][__main__][INFO] - Starting training!
[2025-04-08 00:31:52,122][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 00:31:52,128][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 00:31:52,214][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 00:31:52,422][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 00:31:52,422][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 00:31:53,070][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 00:31:56,155][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 00:31:58,847][__main__][INFO] - Instantiating callbacks...
[2025-04-08 00:31:58,848][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 00:31:58,851][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 00:31:58,852][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 00:31:58,853][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 00:31:58,854][__main__][INFO] - Instantiating loggers...
[2025-04-08 00:31:58,854][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 00:31:58,855][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 00:32:00,261][__main__][INFO] - Logging hyperparameters!
[2025-04-08 00:32:06,796][__main__][INFO] - Starting training!
[2025-04-08 00:32:06,995][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 00:32:06,995][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2025-04-08 00:38:03,089][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 00:38:03,096][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 00:38:03,190][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 00:38:03,601][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 00:38:03,602][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 00:38:04,531][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 00:38:12,348][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 00:38:57,169][__main__][INFO] - Starting testing!
[2025-04-08 00:38:57,170][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-04-08 00:39:00,755][__main__][INFO] - Best ckpt path: None
[2025-04-08 00:39:00,905][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_00-31-52
[2025-04-08 00:39:07,178][__main__][INFO] - Instantiating callbacks...
[2025-04-08 00:39:07,179][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 00:39:07,183][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 00:39:07,184][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 00:39:07,185][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 00:39:07,187][__main__][INFO] - Instantiating loggers...
[2025-04-08 00:39:07,187][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 00:39:07,189][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 00:39:08,523][__main__][INFO] - Logging hyperparameters!
[2025-04-08 00:39:15,422][__main__][INFO] - Starting training!
[2025-04-08 00:39:46,457][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 00:39:46,458][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 00:42:55,342][__main__][INFO] - Starting testing!
[2025-04-08 00:42:55,426][__main__][WARNING] - Best ckpt not found! Using current weights for testing...
[2025-04-08 00:44:22,515][__main__][INFO] - Best ckpt path: None
[2025-04-08 00:44:22,730][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_00-38-02
[2025-04-08 00:54:03,796][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 00:54:03,802][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 00:54:03,884][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 00:54:04,045][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 00:54:04,045][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 00:54:04,496][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 00:54:12,984][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 00:55:13,603][__main__][INFO] - Instantiating callbacks...
[2025-04-08 00:55:13,604][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 00:55:13,608][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 00:55:13,609][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 00:55:13,610][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 00:55:13,611][__main__][INFO] - Instantiating loggers...
[2025-04-08 00:55:13,611][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 00:55:13,613][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 00:55:14,902][__main__][INFO] - Logging hyperparameters!
[2025-04-08 00:55:18,841][__main__][INFO] - Starting training!
[2025-04-08 00:55:48,991][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 00:55:48,992][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 00:56:07,098][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 68, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1014, in _run_stage
    self._run_sanity_check()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1043, in _run_sanity_check
    val_loop.run()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 115, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 375, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_kwargs.values())
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 336, in validation_step
    return self.model(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/overrides/base.py", line 102, in forward
    return self._forward_module.validation_step(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 454, in validation_step
    loss = self.shared_step(batch)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 445, in shared_step
    return self(latent_target, context=context_dict)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 424, in forward
    return self.p_losses(x, t, *args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 417, in p_losses
    pde_loss_val = self.temperature_pde_loss(T_f, T_c)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 280, in temperature_pde_loss
    loss = torch.mean(torch.abs(R_eff_f - R_eff_c))
RuntimeError: The size of tensor a (16) must match the size of tensor b (2) at non-singleton dimension 2
[2025-04-08 00:56:07,113][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_00-54-03
[2025-04-08 01:12:55,979][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 01:12:55,985][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 01:12:56,066][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 01:12:56,237][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 01:12:56,237][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 01:12:56,784][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 01:13:00,170][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 01:13:03,045][__main__][INFO] - Instantiating callbacks...
[2025-04-08 01:13:03,045][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 01:13:03,049][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 01:13:03,050][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 01:13:03,051][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 01:13:03,052][__main__][INFO] - Instantiating loggers...
[2025-04-08 01:13:03,052][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 01:13:03,054][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 01:13:04,277][__main__][INFO] - Logging hyperparameters!
[2025-04-08 01:13:08,816][__main__][INFO] - Starting training!
[2025-04-08 01:13:38,624][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 01:13:38,624][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 02:16:49,991][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 02:16:49,997][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 02:16:50,091][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 02:16:50,377][numexpr.utils][INFO] - Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 02:16:50,378][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 02:16:51,158][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 02:16:55,797][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 02:17:12,619][__main__][INFO] - Instantiating callbacks...
[2025-04-08 02:17:12,620][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 02:17:12,627][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 02:17:12,628][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 02:17:12,628][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 02:17:12,630][__main__][INFO] - Instantiating loggers...
[2025-04-08 02:17:12,630][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 02:17:12,632][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 02:17:13,010][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/home/users/par55/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 92, in _call_target
    return _target_(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/utilities/argparse.py", line 69, in insert_env_defaults
    return fn(self, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 398, in __init__
    self._accelerator_connector = _AcceleratorConnector(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py", line 157, in __init__
    self._set_parallel_devices_and_init_accelerator()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py", line 389, in _set_parallel_devices_and_init_accelerator
    self._devices_flag = accelerator_cls.parse_devices(self._devices_flag)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/accelerators/cuda.py", line 81, in parse_devices
    return _parse_gpu_ids(devices, include_cuda=True)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/fabric/utilities/device_parser.py", line 102, in _parse_gpu_ids
    return _sanitize_gpu_ids(gpus, include_cuda=include_cuda, include_mps=include_mps)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/fabric/utilities/device_parser.py", line 134, in _sanitize_gpu_ids
    raise MisconfigurationException(
lightning.fabric.utilities.exceptions.MisconfigurationException: You requested gpu: [0, 1, 2, 3]
 But your machine only has: [0, 1, 2]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 47, in train
    trainer: Trainer = hydra.utils.instantiate(cfg.trainer, callbacks=callbacks, logger=logger)
  File "/home/users/par55/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
  File "/home/users/par55/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 347, in instantiate_node
    return _call_target(_target_, partial, args, kwargs, full_key)
  File "/home/users/par55/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 97, in _call_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error in call to target 'lightning.pytorch.trainer.trainer.Trainer':
MisconfigurationException('You requested gpu: [0, 1, 2, 3]\n But your machine only has: [0, 1, 2]')
full_key: trainer
[2025-04-08 02:17:13,019][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_02-16-49
[2025-04-08 02:17:53,458][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 02:17:53,470][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 02:17:53,555][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 02:17:53,741][numexpr.utils][INFO] - Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 02:17:53,741][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 02:17:54,394][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 02:17:57,387][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 02:18:00,168][__main__][INFO] - Instantiating callbacks...
[2025-04-08 02:18:00,169][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 02:18:00,172][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 02:18:00,173][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 02:18:00,174][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 02:18:00,174][__main__][INFO] - Instantiating loggers...
[2025-04-08 02:18:00,175][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 02:18:00,177][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 02:18:01,427][__main__][INFO] - Logging hyperparameters!
[2025-04-08 02:18:07,377][__main__][INFO] - Starting training!
[2025-04-08 02:18:29,616][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 02:18:29,617][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
[2025-04-08 02:18:41,804][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 68, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1014, in _run_stage
    self._run_sanity_check()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1043, in _run_sanity_check
    val_loop.run()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 115, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 375, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_kwargs.values())
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 336, in validation_step
    return self.model(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/overrides/base.py", line 102, in forward
    return self._forward_module.validation_step(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 517, in validation_step
    loss = self.shared_step(batch)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 508, in shared_step
    return self(latent_target, context=context_dict)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 487, in forward
    return self.p_losses(x, t, *args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 480, in p_losses
    pde_loss_val = self.temperature_pde_loss(T_f, T_c)
TypeError: LatentDiffusion.temperature_pde_loss() missing 1 required positional argument: 'num_supercells'
[2025-04-08 02:18:41,818][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_02-17-53
[2025-04-08 02:24:52,971][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 02:24:52,984][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 02:24:53,071][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 02:24:53,242][numexpr.utils][INFO] - Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 02:24:53,242][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 02:24:53,778][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 02:24:56,964][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 02:24:59,643][__main__][INFO] - Instantiating callbacks...
[2025-04-08 02:24:59,643][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 02:24:59,646][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 02:24:59,648][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 02:24:59,648][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 02:24:59,649][__main__][INFO] - Instantiating loggers...
[2025-04-08 02:24:59,649][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 02:24:59,651][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 02:25:00,812][__main__][INFO] - Logging hyperparameters!
[2025-04-08 02:25:05,392][__main__][INFO] - Starting training!
[2025-04-08 02:25:24,848][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 02:25:24,849][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
[2025-04-08 02:25:36,111][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 68, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1014, in _run_stage
    self._run_sanity_check()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1043, in _run_sanity_check
    val_loop.run()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 115, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 375, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_kwargs.values())
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 336, in validation_step
    return self.model(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/overrides/base.py", line 102, in forward
    return self._forward_module.validation_step(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 517, in validation_step
    loss = self.shared_step(batch)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 508, in shared_step
    return self(latent_target, context=context_dict)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 487, in forward
    return self.p_losses(x, t, *args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 480, in p_losses
    pde_loss_val = self.temperature_pde_loss(T_f, T_c,42)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 339, in temperature_pde_loss
    R_f = self._compute_supercell_flux_ratio_field_batch(T_f, num_supercells=num_supercells, dx=1.0, dy=1.0, eps=1e-6)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 294, in _compute_supercell_flux_ratio_field_batch
    raise ValueError("H and W must be evenly divisible by num_supercells")
ValueError: H and W must be evenly divisible by num_supercells
[2025-04-08 02:25:36,118][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_02-24-52
[2025-04-08 02:27:58,955][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 02:27:58,962][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 02:27:59,042][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 02:27:59,219][numexpr.utils][INFO] - Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 02:27:59,220][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 02:27:59,880][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 02:28:09,390][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 02:28:12,096][__main__][INFO] - Instantiating callbacks...
[2025-04-08 02:28:12,097][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 02:28:12,100][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 02:28:12,101][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 02:28:12,102][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 02:28:12,102][__main__][INFO] - Instantiating loggers...
[2025-04-08 02:28:12,102][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 02:28:12,104][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 02:28:13,240][__main__][INFO] - Logging hyperparameters!
[2025-04-08 02:28:17,979][__main__][INFO] - Starting training!
[2025-04-08 02:28:37,012][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 02:28:37,013][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
[2025-04-08 02:28:47,361][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 68, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 973, in _run
    results = self._run_stage()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1014, in _run_stage
    self._run_sanity_check()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1043, in _run_sanity_check
    val_loop.run()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 177, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 115, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 375, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_kwargs.values())
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 291, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 336, in validation_step
    return self.model(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/overrides/base.py", line 102, in forward
    return self._forward_module.validation_step(*inputs, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 517, in validation_step
    loss = self.shared_step(batch)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 508, in shared_step
    return self(latent_target, context=context_dict)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 487, in forward
    return self.p_losses(x, t, *args, **kwargs)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 480, in p_losses
    pde_loss_val = self.temperature_pde_loss(T_f, T_c,12)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 339, in temperature_pde_loss
    R_f = self._compute_supercell_flux_ratio_field_batch(T_f, num_supercells=num_supercells, dx=1.0, dy=1.0, eps=1e-6)
  File "/usr/project/xtmp/par55/DiffScaler/src/models/ldm_module.py", line 294, in _compute_supercell_flux_ratio_field_batch
    raise ValueError("H and W must be evenly divisible by num_supercells")
ValueError: H and W must be evenly divisible by num_supercells
[2025-04-08 02:28:47,368][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_02-27-58
[2025-04-08 02:30:18,391][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 02:30:18,398][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 02:30:18,476][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 02:30:18,669][numexpr.utils][INFO] - Note: NumExpr detected 24 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 02:30:18,670][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 02:30:19,162][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 02:30:22,365][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 02:30:25,091][__main__][INFO] - Instantiating callbacks...
[2025-04-08 02:30:25,091][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 02:30:25,095][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 02:30:25,096][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 02:30:25,096][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 02:30:25,097][__main__][INFO] - Instantiating loggers...
[2025-04-08 02:30:25,097][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 02:30:25,099][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 02:30:26,265][__main__][INFO] - Logging hyperparameters!
[2025-04-08 02:30:30,986][__main__][INFO] - Starting training!
[2025-04-08 02:30:50,554][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 02:30:50,555][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
[2025-04-08 02:31:50,209][__main__][INFO] - Starting testing!
[2025-04-08 02:37:16,586][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_01-12-55/checkpoints/epoch_000.ckpt
[2025-04-08 02:37:16,758][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_01-12-55
[2025-04-08 02:37:16,759][src.utils.utils][INFO] - Retrieved metric value! <val/loss=nan>
[2025-04-08 02:40:15,335][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 02:40:15,340][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 02:40:15,418][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 02:40:15,572][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 02:40:15,572][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 02:40:16,008][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 02:40:19,230][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 02:40:22,538][__main__][INFO] - Instantiating callbacks...
[2025-04-08 02:40:22,538][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 02:40:22,542][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 02:40:22,543][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 02:40:22,544][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 02:40:22,544][__main__][INFO] - Instantiating loggers...
[2025-04-08 02:40:22,544][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 02:40:22,546][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 02:40:23,902][__main__][INFO] - Logging hyperparameters!
[2025-04-08 02:40:27,959][__main__][INFO] - Starting training!
[2025-04-08 02:40:52,290][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 02:40:52,290][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 02:44:47,362][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 02:44:47,368][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 02:44:47,445][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 02:44:47,620][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 02:44:47,620][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 02:44:48,142][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 02:44:51,706][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 02:44:59,659][__main__][INFO] - Instantiating callbacks...
[2025-04-08 02:44:59,660][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 02:44:59,663][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 02:44:59,665][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 02:44:59,665][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 02:44:59,666][__main__][INFO] - Instantiating loggers...
[2025-04-08 02:44:59,666][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 02:44:59,667][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 02:45:00,906][__main__][INFO] - Logging hyperparameters!
[2025-04-08 02:45:05,199][__main__][INFO] - Starting training!
[2025-04-08 02:45:33,586][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 02:45:33,587][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 02:51:36,437][__main__][INFO] - Starting testing!
[2025-04-08 02:55:45,425][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_02-30-18/checkpoints/epoch_000.ckpt
[2025-04-08 02:55:45,710][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_02-30-18
[2025-04-08 02:55:45,711][src.utils.utils][INFO] - Retrieved metric value! <val/loss=nan>
[2025-04-08 03:06:24,492][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 03:06:24,499][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 03:06:24,592][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 03:06:24,998][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 03:06:24,998][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 03:06:25,902][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 03:06:31,204][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 03:06:48,110][__main__][INFO] - Instantiating callbacks...
[2025-04-08 03:06:48,111][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 03:06:48,116][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 03:06:48,117][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 03:06:48,118][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 03:06:48,121][__main__][INFO] - Instantiating loggers...
[2025-04-08 03:06:48,121][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 03:06:48,123][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 03:06:49,372][__main__][INFO] - Logging hyperparameters!
[2025-04-08 03:06:56,903][__main__][INFO] - Starting training!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [2025-04-08 03:07:29,347][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 03:07:29,348][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 03:07:55,587][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 03:07:55,587][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 03:55:55,813][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 03:55:55,819][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 03:55:55,908][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 03:55:56,256][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 03:55:56,256][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 03:55:56,980][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 03:56:06,251][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 03:57:13,556][__main__][INFO] - Instantiating callbacks...
[2025-04-08 03:57:13,557][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 03:57:13,561][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 03:57:13,562][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 03:57:13,562][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 03:57:13,567][__main__][INFO] - Instantiating loggers...
[2025-04-08 03:57:13,567][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 03:57:13,569][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 03:57:15,232][__main__][INFO] - Logging hyperparameters!
[2025-04-08 03:57:22,708][__main__][INFO] - Starting training!
[2025-04-08 03:57:55,144][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 03:57:55,145][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 05:36:29,640][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 05:36:29,648][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 05:36:29,731][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 05:36:29,958][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 05:36:29,958][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 05:36:30,610][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 05:36:34,381][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 05:36:37,255][__main__][INFO] - Instantiating callbacks...
[2025-04-08 05:36:37,256][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 05:36:37,259][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 05:36:37,260][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 05:36:37,260][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 05:36:37,261][__main__][INFO] - Instantiating loggers...
[2025-04-08 05:36:37,261][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 05:36:37,262][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 05:36:38,341][__main__][INFO] - Logging hyperparameters!
[2025-04-08 05:36:41,901][__main__][INFO] - Starting training!
[2025-04-08 05:37:10,162][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 05:37:10,163][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 05:43:03,437][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 05:43:03,444][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 05:43:03,536][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 05:43:03,933][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 05:43:03,934][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 05:43:04,672][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 05:43:10,009][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 05:43:26,737][__main__][INFO] - Instantiating callbacks...
[2025-04-08 05:43:26,738][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 05:43:26,742][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 05:43:26,743][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 05:43:26,744][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 05:43:26,745][__main__][INFO] - Instantiating loggers...
[2025-04-08 05:43:26,745][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 05:43:26,747][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 05:43:27,903][__main__][INFO] - Logging hyperparameters!
[2025-04-08 05:43:35,700][__main__][INFO] - Starting training!
[2025-04-08 05:44:07,194][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 05:44:07,195][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 11:11:16,498][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 11:11:16,506][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 11:11:16,606][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 11:11:17,193][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 11:11:17,193][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 11:11:18,373][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 11:11:23,889][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 11:11:40,974][__main__][INFO] - Instantiating callbacks...
[2025-04-08 11:11:40,975][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 11:11:40,984][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 11:11:40,985][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 11:11:40,986][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 11:11:40,987][__main__][INFO] - Instantiating loggers...
[2025-04-08 11:11:[2025-04-08 11:11:41,467][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 11:11:41,475][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-0[2025-04-08 11:11:43,635][__main__][INFO] - Partial training mode: lo[2025-04-08 11:11:53,184][__main__][INFO] - Starting training!
trained_models/LDM_residual_2mT.ckpt without optimizer state.
s but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 11:11:41,701][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 11:11:42,237][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 11:11:45,986][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 11:11:48,672][__main__][INFO] - Instantiating callbacks...
[2025-04-08 11:11:48,672][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 11:11:48,675][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 11:11:48,676][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 11:11:48,677][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 11:11:48,677][__main__][INFO] - Instantiating loggers...
[2025-04-08 11:11:48,677][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 11:11:48,679][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 11:11:49,872][__main__][INFO] - Logging hyperparameters!
[2025-04-08 11:11:55,468][__main__][INFO] - Starting training!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [2025-04-08 11:12:27,351][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 11:12:27,351][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-0[2025-04-08 11:12:35,797][__main__][INFO] - Starting training!
ecent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 68, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 164, in setup
    self.configure_ddp()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 269, in configure_ddp
    self.model = self._setup_model(_LightningModuleWrapperBase(self.model))
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 183, in _setup_model
    return DistributedDataParallel(module=model, device_ids=device_ids, **self._ddp_kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
    _verify_param_shape_across_processes(self.process_group, parameters)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
    return dist._verify_params_across_processes(process_group, tensors, logger)
RuntimeError: DDP expects same model across all ranks, but Rank 0 has 192 params, while rank 1 has inconsistent 170 params.
[2025-04-08 11:12:31,480][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_11-11-16
[2025-04-08 11:12:35,585][__main__][INFO] - Instantiating callbacks...
[2025-04-08 11:12:35,586][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 11:12:35,589][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 11:12:35,590][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 11:12:35,590][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 11:12:35,591][__main__][INFO] - Instantiating loggers...
[2025-04-08 11:12:35,592][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 11:12:35,593][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 11:12:36,755][__main__][INFO] - Logging hyperparameters!
 Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 11:12:37,432][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 11:12:41,909][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 68, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 164, in setup
    self.configure_ddp()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 269, in configure_ddp
    self.model = self._setup_model(_LightningModuleWrapperBase(self.model))
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 183, in _setup_model
    return DistributedDataParallel(module=model, device_ids=device_ids, **self._ddp_kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
    _verify_param_shape_across_processes(self.process_group, parameters)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
    return dist._verify_params_across_processes(process_group, tensors, logger)
RuntimeError: DDP expects same model across all ranks, but Rank 0 has 192 params, while rank 1 has inconsistent 170 params.
[2025-04-08 11:12:41,917][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_11-11-36
[2025-04-08 11:13:06,797][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 11:13:06,798][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 11:13:11,873][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 11:13:11,873][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 11:13:24,123][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 11:13:24,131][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 11:13:24,214][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 11:13:24,432][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 11:13:24,432][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 11:13:25,324][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 11:13:28,892][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 11:13:31,927][__main__][INFO] - Instantiating callbacks...
[2025-04-08 11:13:31,927][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 11:13:31,931][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 11:13:31,931][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 11:13:31,932][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 11:13:31,932][__main__][INFO] - Instantiating loggers...
[2025-04-08 11:13:31,933][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 11:13:31,934][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 11:13:33,084][__main__][INFO] - Logging hyperparameters!
[2025-04-08 11:13:38,074][__main__][INFO] - Starting training!
[2025-04-08 11:14:10,637][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 11:14:10,638][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 11:16:13,513][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 11:16:13,520][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 11:16:13,614][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 11:16:14,060][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 11:16:14,060][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 11:16:15,061][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 11:16:20,390][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 11:16:36,457][__main__][INFO] - Instantiating callbacks...
[2025-04-08 11:16:36,458][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 11:16:36,464][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 11:16:36,464][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 11:16:36,465][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 11:16:36,466][__main__][INFO] - Instantiating loggers...
[2025-04-08 11:16:36,467][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 11:16:36,468][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 11:16:37,644][__main__][INFO] - Logging hyperparameters!
                                                                                                                             [2025-04-08 11:16:43,983][__main__][INFO] - Starting training!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [2025-04-08 11:17:17,839][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 11:17:17,840][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 11:17:22,483][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 11:17:22,484][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 11:17:55,291][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 11:17:55,297][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 11:17:55,380][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 11:17:55,583][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 11:17:55,583][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 11:17:56,307][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 11:18:03,448][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 11:18:03,455][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 11:18:03,539][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 11:18:03,773][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 11:18:03,773][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 11:18:04,411][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 11:18:08,099][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 11:18:11,117][__main__][INFO] - Instantiating callbacks...
[2025-04-08 11:18:11,117][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 11:18:11,120][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 11:18:11,121][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 11:18:11,122][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 11:18:11,122][__main__][INFO] - Instantiating loggers...
[2025-04-08 11:18:11,122][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 11:18:11,124][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 11:18:14,288][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 11:18:14,296][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 11:18:14,376][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 11:18:14,566][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 11:18:14,567][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 11:18:15,248][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 11:18:18,944][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 11:18:21,991][__main__][INFO] - Instantiating callbacks...
[2025-04-08 11:18:21,992][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 11:18:21,995][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 11:18:21,997][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 11:18:21,997][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 11:18:21,998][__main__][INFO] - Instantiating loggers...
[2025-04-08 11:18:21,998][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 11:18:21,999][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 11:18:23,351][__main__][INFO] - Logging hyperparameters!
[2025-04-08 11:18:29,018][__main__][INFO] - Starting training!
[2025-04-08 11:18:29,813][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 11:18:29,821][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 11:18:29,904][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 11:18:30,125][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 11:18:30,125][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 11:18:30,770][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 11:18:36,503][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 11:18:46,859][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 11:18:46,870][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 11:18:46,952][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 11:18:47,168][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 11:18:47,169][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 11:18:48,065][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
47,756][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 11:18:47,758][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 11:18:49,323][__main__][INFO] - Logging hyperparameters!
ading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 11:18:54,462][__main__][INFO] - Instantiating callbacks...
[2025-04-08 11:18:54,463][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 11:18:54,467][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 11:18:54,467][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 11:18:54,468][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 11:18:54,468][__main__][INFO] - Instantiating loggers...
[2025-04-08 11:18:54,469][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 11:18:54,470][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 11:18:55,648][__main__][INFO] - Logging hyperparameters!
[2025-04-08 11:19:00,836][__main__][INFO] - Starting training!
[2025-04-08 11:19:01,742][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 11:19:01,742][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 11:19:05,735][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 68, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 164, in setup
    self.configure_ddp()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 269, in configure_ddp
    self.model = self._setup_model(_LightningModuleWrapperBase(self.model))
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 183, in _setup_model
    return DistributedDataParallel(module=model, device_ids=device_ids, **self._ddp_kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
    _verify_param_shape_across_processes(self.process_group, parameters)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
    return dist._verify_params_across_processes(process_group, tensors, logger)
RuntimeError: DDP expects same model across all ranks, but Rank 0 has 170 params, while rank 1 has inconsistent 192 params.
[2025-04-08 11:19:05,742][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_11-18-14
[2025-04-08 11:19:08,962][__main__][INFO] - Instantiating callbacks...
[2025-04-08 11:19:08,963][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 11:19:08,967][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 11:19:08,968][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 11:19:08,969][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 11:19:08,969][__main__][INFO] - Instantiating loggers...
[2025-04-08 11:19:08,969][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 11:19:08,971][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 11:19:10,343][__main__][INFO] - Logging hyperparameters!
[2025-04-08 11:19:15,877][__main__][INFO] - Starting training!
[2025-04-08 11:19:25,498][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 11:19:25,499][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 11:19:32,108][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 11:19:32,108][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 164, in setup
    self.configure_ddp()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 269, in configure_ddp
    self.model = self._setup_model(_LightningModuleWrapperBase(self.model))
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 183, in _setup_model
    return DistributedDataParallel(module=model, device_ids=device_ids, **self._ddp_kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
    _verify_param_shape_across_processes(self.process_group, parameters)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
    return dist._verify_params_across_processes(process_group, tensors, logger)
RuntimeError: DDP expects same model across all ranks, but Rank 0 has 170 params, while rank 1 has inconsistent 192 params.
[2025-04-08 11:19:29,718][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_11-17-55
[2025-04-08 11:19:48,942][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 11:19:48,942][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 11:48:18,503][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 11:48:28,506][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:48:38,509][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:48:48,513][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:48:58,521][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:49:08,529][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:49:18,536][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:49:28,544][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:49:38,553][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:49:48,561][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:49:58,567][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:50:08,573][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:50:18,582][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:50:28,589][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:50:38,595][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:50:48,604][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:50:58,611][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:51:08,618][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:51:18,623][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:51:28,630][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:51:38,638][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:51:48,646][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:51:58,653][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:52:08,660][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:52:18,667][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:52:28,676][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:52:38,678][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:52:48,686][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:52:58,696][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:53:08,704][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:53:18,710][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:53:28,719][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:53:38,728][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:53:48,735][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:53:58,742][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:54:08,750][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:54:18,757][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:54:28,758][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:54:38,767][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:54:48,775][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:54:58,784][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:55:08,791][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:55:18,799][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:55:28,806][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:55:38,814][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:55:48,822][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:55:58,829][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:56:08,837][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:56:18,843][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:56:28,851][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:56:38,859][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:56:48,866][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:56:58,873][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:57:08,880][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:57:18,891][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:57:28,892][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:57:38,899][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:57:48,906][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:57:58,913][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:58:08,921][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:58:18,926][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:58:28,929][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:58:38,938][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:58:48,947][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:58:58,956][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:59:08,965][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:59:18,973][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:59:28,983][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:59:38,992][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:59:49,003][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 11:59:59,013][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:00:09,016][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:00:19,025][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:00:29,036][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:00:39,042][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:00:49,051][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:00:59,061][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:01:09,065][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:01:19,075][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:01:29,079][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:01:39,085][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:01:49,091][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:01:59,101][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:02:09,112][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:02:19,120][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:02:29,130][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:02:39,137][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:02:49,143][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:02:59,151][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:03:09,158][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:03:19,167][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:03:29,171][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:03:39,179][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:03:49,189][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:03:59,192][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:04:09,195][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:04:19,202][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:04:29,206][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:04:39,214][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:04:49,223][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:04:59,227][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:05:09,230][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:05:19,233][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:05:29,237][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:05:39,240][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:05:49,245][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:05:59,252][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:06:09,259][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:06:19,269][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:06:29,274][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:06:39,279][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:06:49,285][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:06:59,290][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:07:09,296][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:07:19,301][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:07:29,310][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:07:39,319][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:07:49,328][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:07:59,337][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:08:09,345][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:08:19,354][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:08:29,359][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:08:39,370][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:08:49,379][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:08:59,384][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:09:09,389][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:09:19,390][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:09:29,399][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:09:39,409][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:09:49,419][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:09:59,426][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:10:09,435][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:10:19,444][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:10:29,450][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:10:39,460][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:10:49,470][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:10:59,479][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:11:09,489][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:11:19,498][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:11:29,509][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:11:39,520][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:11:49,530][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:11:59,540][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:12:09,551][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:12:19,561][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:12:29,571][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:12:39,581][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:12:49,583][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:12:59,593][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:13:09,603][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:13:19,614][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:13:29,624][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:13:39,625][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:13:49,635][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:13:59,645][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:14:09,656][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:14:19,667][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:14:29,677][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:14:39,688][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:14:49,698][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:14:59,709][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:15:09,720][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:15:19,729][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:15:29,738][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:15:39,744][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:15:49,751][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:15:59,752][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:16:09,763][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:16:19,772][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:16:29,782][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:16:39,792][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:16:49,802][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:16:59,804][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:17:09,814][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:17:19,824][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:17:29,835][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:17:39,845][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:17:49,855][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:17:59,864][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:18:09,875][torch.distributed.distributed_c10d][INFO] - Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:18:18,545][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 68, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 931, in _run
    self.strategy.setup_environment()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 143, in setup_environment
    self.setup_distributed()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 192, in setup_distributed
    _init_dist_connection(self.cluster_environment, self._process_group_backend, timeout=self._timeout)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/fabric/utilities/distributed.py", line 246, in _init_dist_connection
    torch.distributed.init_process_group(torch_distributed_backend, rank=global_rank, world_size=world_size, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 932, in init_process_group
    _store_based_barrier(rank, store, timeout)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 469, in _store_based_barrier
    raise RuntimeError(
RuntimeError: Timed out initializing process group in store based barrier on rank: 0, for key: store_based_barrier_key:1 (world_size=4, worker_count=2, timeout=0:30:00)
[2025-04-08 12:18:18,564][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_11-18-03
[2025-04-08 13:03:00,966][__main__][INFO] - Starting testing!
[2025-04-08 13:06:31,876][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_11-12-06/checkpoints/epoch_000.ckpt
[2025-04-08 13:06:32,064][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_11-12-06
[2025-04-08 13:06:32,064][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.24097399413585663>
[2025-04-08 13:06:35,044][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_11-12-15/checkpoints/epoch_000.ckpt
[2025-04-08 13:06:35,283][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_11-12-15
[2025-04-08 13:06:35,283][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.24264322221279144>
[2025-04-08 13:09:40,258][__main__][INFO] - Starting testing!
[2025-04-08 13:11:36,657][__main__][INFO] - Starting testing!
[2025-04-08 13:11:39,474][__main__][INFO] - Starting testing!
[2025-04-08 13:13:10,981][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_11-16-35/checkpoints/epoch_000.ckpt
[2025-04-08 13:13:11,155][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_11-16-35
[2025-04-08 13:13:11,156][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.26312020421028137>
[2025-04-08 13:13:20,665][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_11-16-13/checkpoints/epoch_000.ckpt
[2025-04-08 13:13:20,915][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_11-16-13
[2025-04-08 13:13:20,915][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.26281267404556274>
[2025-04-08 13:14:47,318][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_11-18-46/checkpoints/epoch_000.ckpt
[2025-04-08 13:14:47,508][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_11-18-46
[2025-04-08 13:14:47,509][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.24123366177082062>
[2025-04-08 13:15:15,317][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_11-18-29/checkpoints/epoch_000.ckpt
[2025-04-08 13:15:15,591][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_11-18-29
[2025-04-08 13:15:15,591][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.24123388528823853>
[2025-04-08 13:15:29,468][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_11-13-24/checkpoints/epoch_000.ckpt
[2025-04-08 13:15:29,645][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_11-13-24
[2025-04-08 13:15:29,645][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.24326136708259583>
[2025-04-08 14:04:55,041][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 14:04:55,048][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 14:04:55,125][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 14:04:55,311][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 14:04:55,311][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 14:04:55,963][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 14:04:59,072][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 14:05:01,523][__main__][INFO] - Instantiating callbacks...
[2025-04-08 14:05:01,523][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 14:05:01,527][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 14:05:01,528][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 14:05:01,529][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 14:05:01,529][__main__][INFO] - Instantiating loggers...
[2025-04-08 14:05:01,529][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 14:05:01,531][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 14:05:03,121][__main__][INFO] - Logging hyperparameters!
[2025-04-08 14:05:08,606][__main__][INFO] - Starting training!
[2025-04-08 14:05:19,084][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 14:05:19,091][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 14:05:19,171][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 14:05:19,396][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 14:05:19,396][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 14:05:20,297][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 14:05:23,792][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 14:05:26,789][__main__][INFO] - Instantiating callbacks...
[2025-04-08 14:05:26,789][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 14:05:26,793][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 14:05:26,794][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 14:05:26,794][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 14:05:26,795][__main__][INFO] - Instantiating loggers...
[2025-04-08 14:05:26,795][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 14:05:26,796][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 14:05:31,343][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 14:05:31,350][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 14:05:31,430][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 14:05:31,735][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 14:05:31,735][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 14:05:32,625][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 14:05:36,273][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 14:05:38,516][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 14:05:38,523][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 14:05:38,606][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 14:05:38,819][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 14:05:38,819][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 14:05:39,633][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 14:05:43,372][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
kages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 164, in setup
    self.configure_ddp()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 269, in configure_ddp
    self.model = self._setup_model(_LightningModuleWrapperBase(self.model))
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 183, in _setup_model
    return DistributedDataParallel(module=model, device_ids=device_ids, **self._ddp_kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
    _verify_param_shape_across_processes(self.process_group, parameters)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
    return dist._verify_params_across_processes(process_group, tensors, logger)
RuntimeError: DDP expects same model across all ranks, but Rank 0 has 418 params, while rank 1 has inconsistent 170 params.
[2025-04-08 14:05:42,759][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_14-04-54
[2025-04-08 14:05:48,053][__main__][INFO] - Instantiating callbacks...
[2025-04-08 14:05:48,053][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 14:05:48,057][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 14:05:48,058][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 14:05:48,059][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 14:05:48,059][__main__][INFO] - Instantiating loggers...
[2025-04-08 14:05:48,060][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 14:05:48,061][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 14:05:49,766][__main__][INFO] - Logging hyperparameters!
[2025-04-08 14:05:52,758][__main__][INFO] - Starting training!
[2025-04-08 14:05:55,814][__main__][INFO] - Starting training!
[2025-04-08 14:06:04,460][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 14:06:04,466][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 14:06:04,542][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 14:06:04,702][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 14:06:04,702][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 14:06:05,337][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 14:06:08,626][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
kages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 164, in setup
    self.configure_ddp()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 269, in configure_ddp
    self.model = self._setup_model(_LightningModuleWrapperBase(self.model))
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 183, in _setup_model
    return DistributedDataParallel(module=model, device_ids=device_ids, **self._ddp_kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
    _verify_param_shape_across_processes(self.process_group, parameters)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
    return dist._verify_params_across_processes(process_group, tensors, logger)
RuntimeError: DDP expects same model across all ranks, but Rank 0 has 170 params, while rank 1 has inconsistent 192 params.
[2025-04-08 14:06:08,250][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_14-05-18
[2025-04-08 14:06:11,126][__main__][INFO] - Instantiating callbacks...
[2025-04-08 14:06:11,126][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 14:06:11,129][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 14:06:11,131][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 14:06:11,131][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 14:06:11,132][__main__][INFO] - Instantiating loggers...
[2025-04-08 14:06:11,132][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 14:06:11,134][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 14:06:12,694][__main__][INFO] - Logging hyperparameters!
[2025-04-08 14:06:17,769][__main__][INFO] - Starting training!
[2025-04-08 14:06:20,755][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 14:06:20,755][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 14:06:26,702][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 68[2025-04-08 14:06:29,383][src.utils.utils][ERROR] - 
Traceback (most recent call last):
  File "/usr/project/xtmp/par55/DiffScaler/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/usr/project/xtmp/par55/DiffScaler/src/train.py", line 68, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 529, in fit
    call._call_and_handle_interrupt(
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 41, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 91, in launch
    return function(*args, **kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 568, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 949, in _run
    self.strategy.setup(self)
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 164, in setup
    self.configure_ddp()
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 269, in configure_ddp
    self.model = self._setup_model(_LightningModuleWrapperBase(self.model))
  File "/home/users/par55/.local/lib/python3.10/site-packages/lightning/pytorch/strategies/ddp.py", line 183, in _setup_model
    return DistributedDataParallel(module=model, device_ids=device_ids, **self._ddp_kwargs)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 674, in __init__
    _verify_param_shape_across_processes(self.process_group, parameters)
  File "/home/users/par55/.local/lib/python3.10/site-packages/torch/distributed/utils.py", line 118, in _verify_param_shape_across_processes
    return dist._verify_params_across_processes(process_group, tensors, logger)
RuntimeError: DDP expects same model across all ranks, but Rank 0 has 192 params, while rank 1 has inconsistent 34 params.
[2025-04-08 14:06:29,389][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_14-05-38
[2025-04-08 14:06:33,299][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 14:06:33,307][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 14:06:33,387][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 14:06:33,568][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 14:06:33,568][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 14:06:34,241][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 14:06:37,907][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 14:06:41,132][__main__][INFO] - Instantiating callbacks...
[2025-04-08 14:06:41,133][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 14:06:41,137][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 14:06:41,138][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 14:06:41,138][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 14:06:41,139][__main__][INFO] - Instantiating loggers...
[2025-04-08 14:06:41,139][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 14:06:41,140][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 14:06:42,358][__main__][INFO] - Logging hyperparameters!
[2025-04-08 14:06:46,453][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 14:06:46,454][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 14:07:13,811][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 14:07:13,811][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 14:13:31,654][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 14:13:31,661][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 14:13:31,737][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 14:13:31,891][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 14:13:31,891][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 14:13:32,552][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 14:13:35,765][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 14:13:38,322][__main__][INFO] - Instantiating callbacks...
[2025-04-08 14:13:38,323][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 14:13:38,326][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 14:13:38,327][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 14:13:38,328][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 14:13:38,328][__main__][INFO] - Instantiating loggers...
[2025-04-08 14:13:38,329][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 14:13:38,330][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 14:13:39,699][__main__][INFO] - Logging hyperparameters!
[2025-04-08 14:13:44,922][__main__][INFO] - Starting training!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          [2025-04-08 14:14:15,841][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 14:14:15,841][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 14:14:26,958][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 14:14:26,959][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 14:17:12,906][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 14:17:12,913][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 14:17:12,993][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 14:17:13,203][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 14:17:13,203][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 14:17:13,903][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 14:17:17,759][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 14:17:21,136][__main__][INFO] - Instantiating callbacks...
[2025-04-08 14:17:21,137][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 14:17:21,140][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 14:17:21,141][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 14:17:21,142][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 14:17:21,142][__main__][INFO] - Instantiating loggers...
[2025-04-08 14:17:21,142][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 14:17:21,144][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 14:17:22,327][__main__][INFO] - Logging hyperparameters!
[2025-04-08 14:17:28,103][__main__][INFO] - Starting training!
[2025-04-08 14:17:58,836][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 14:17:58,837][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [2025-04-08 16:08:06,778][__main__][INFO] - Starting testing!
                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [2025-04-08 16:11:41,926][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_14-17-12/checkpoints/epoch_000.ckpt
[2025-04-08 16:11:42,219][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_14-17-12
[2025-04-08 16:11:42,219][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.24079151451587677>
[2025-04-08 16:13:07,153][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_14-13-31/checkpoints/epoch_000.ckpt
[2025-04-08 16:13:07,399][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_14-13-31
[2025-04-08 16:13:07,400][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.24123823642730713>
[2025-04-08 19:11:51,330][src.utils.utils][INFO] - Enforcing tags! <cfg.extras.enforce_tags=True>
[2025-04-08 19:11:51,349][src.utils.utils][INFO] - Printing config tree with Rich! <cfg.extras.print_config=True>
[2025-04-08 19:11:51,460][__main__][INFO] - Instantiating datamodule <src.data.downscaling_datamodule.DownscalingDataModule>
[2025-04-08 19:11:51,713][numexpr.utils][INFO] - Note: NumExpr detected 48 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-04-08 19:11:51,714][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-04-08 19:11:52,522][__main__][INFO] - Instantiating model <src.models.ldm_module.LatentDiffusion>
[2025-04-08 19:11:56,261][__main__][INFO] - Partial training mode: loading model weights from /usr/project/xtmp/par55/DiffScaler/pretrained_models/LDM_residual_2mT.ckpt without optimizer state.
[2025-04-08 19:11:59,042][__main__][INFO] - Instantiating callbacks...
[2025-04-08 19:11:59,043][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>
[2025-04-08 19:11:59,046][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>
[2025-04-08 19:11:59,047][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>
[2025-04-08 19:11:59,047][src.utils.instantiators][INFO] - Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>
[2025-04-08 19:11:59,048][__main__][INFO] - Instantiating loggers...
[2025-04-08 19:11:59,048][src.utils.instantiators][INFO] - Instantiating logger <lightning.pytorch.loggers.tensorboard.TensorBoardLogger>
[2025-04-08 19:11:59,050][__main__][INFO] - Instantiating trainer <lightning.pytorch.trainer.Trainer>
[2025-04-08 19:12:00,394][__main__][INFO] - Logging hyperparameters!
[2025-04-08 19:12:07,781][__main__][INFO] - Starting training!
[2025-04-08 19:12:44,430][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-04-08 19:12:44,431][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2025-04-08 21:04:46,291][__main__][INFO] - Starting testing!
[2025-04-08 21:08:25,970][__main__][INFO] - Best ckpt path: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_19-11-51/checkpoints/epoch_000.ckpt
[2025-04-08 21:08:26,138][src.utils.utils][INFO] - Output dir: /usr/project/xtmp/par55/DiffScaler/logs/train/runs/2025-04-08_19-11-51
[2025-04-08 21:08:26,138][src.utils.utils][INFO] - Retrieved metric value! <val/loss=0.2412298023700714>
